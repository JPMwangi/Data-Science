We'll investigate logistic regression, a type of regression analysis that classifies data into two categories. You'll learn how to build a binomial logistic regression model and how data professionals use this type of model to gain insights from their data.
### Foundations of logistic regression
##### Welcome to the module
Linear regression can help us answer different kinds of questions. For example, we could consider the factors that contribute to penguins body mass or factors that affect click-throughs on a website. We are going to expand the kinds of questions we can ask. We'll focus on modelling the probability that an event will occur. There are lots of problems that we can explore. For example, what factors influence the odds that a customer buys from a company again? What impacts the likelihood a worker receives high performance ratings? What contributes to a user commenting or not commenting on a video?
Logistic regression can help you answer these questions. Logistic regression is a technique that models a categorical dependent variable (Y) based on one or more independent variables (X). The dependent variable can have two or more possible discrete values. We'll focus mostly on binomial logistic regression.
Binomial logistic regression is a technique that models the probability of an observation falling into one of two categories, based on one or more independent variables. We use a binary variable Y to indicate the category.
For example, let's say that you're a data professional working for a basketball team, and you want to understand the probability that any given player on your team will score more than 10 points in the game. There are many variables you might want to consider. For example, how well did the player perform last season? What's their average playing time? How many points did they score this season?
This might seem like a multiple regression problem, but consider the outcome variable, whether or not the player will score more than 10 points in a basketball game. This is a binary outcome variable. Since there are only two possible outcomes, we can't draw a best fit line in the same we do for linear regression. 
What you'll learn: binomial logistic regression, maximum likelihood estimation, logistic regression in Python, evaluating logistic regression, and interpreting results for sharing them with stakeholders and other team members.
##### Find the best logistic regression model for your data
Binomial logistic regression is a method for modelling the probability of a binary outcome. But just like any other statistical method, we have to make assumptions about the data to have confidence in the results. We are going to discuss the main assumptions of binomial logistic regression and consider how to find the best logistic regression model given a set of data.
Our goal is to understand how logistic regression works but not in every detail since its a bit more complex than linear regression. In PACE workflow, we consider the assumptions of the model as we analyze our approach. We can figure out if a logistic regression model is the best choice to address the question we're working on. The assumptions of binomial logistic regression are:
###### Linearity
In binomial logistic regression, the linearity assumption states that there should be a linear relationship between each X variable and the logit of the probability that Y equals 1.
The linearity assumption is the key assumption that explains how we can estimate a logistic regression model that fits the data best. To understand logit, we must first define the odds. The odds of a given probability P is equal to: $odds = P / 1-P$ . Think of this equation as the probability of P occurring divided by the probability of P not occurring. 
The logit or log-odds function is the logarithms of the odds of a given probability. So the logit of the probability of P is: $logit (P) = log(P / 1-P)$ . Logit is the most common link function used to linearly relate the X variables to the probability of Y. 
To translate this into less technical language, let's explore the basketball example further. If you're working for a basketball team as a data practitioner, you'll want to know the likelihood of your players scoring many points in a game, rather than the other outcome, that they don't score many points.
By assuming that there is a linear relationship between the X variables and the logit of the probability that Y equals our outcome of interest or 1. You can then find some beta coefficient that explains the data you've observed. You can write the logit of P in terms of the X variables. So the logit of P equals: 
- $logit(P) = log(P / 1-P) = B_o + B_1 X_1 + B_2 X_2 ... B_n X_n$  
Where $n$ is the number of independent variables you are considering in your model. And like linear regression, we don't want just any set of beta coefficients, we want the best set of beta coefficients to make sure our model fits the data. In linear regression, we minimize the sum of squared residuals, which is a measure of error, to figure out the best model. In logistic regression, we often use maximum likelihood estimation to find the best logistic regression model.
Maximum likelihood estimation (MLE) is a technique for estimating the beta parameters that maximize the likelihood of the model producing the observed data. Likelihood is the probability of observing the actual data, given some set of beta parameters. 
###### Independent observations
This is an assumption related to how the data is collected. Because the observations are assumed to be independent, we can say that : $P(A$ AND $B) = P(A) * P(B)$ . Therefore, if you have n basketball players on your team, you can calculate the likelihood of observing the outcome for each player, and then multiply all the likelihoods together to determine the likelihood of observing all of the sample data.
The best logistic regression model estimates the set of beta coefficients that maximizes the likelihood of observing all of the sample data.
###### No multicollinearity
We assume that there is little to no multicollinearity between independent variables. If we include multiple X variables, they should not be highly correlated with one another, just like linear regression. 
###### No extreme outliers
We assume that there are no extreme outliers in the dataset. Outliers are a complex topic in regression and can be detected after the model is fit. Sometimes its appropriate to transform or adjust variables to maintain model validity. Other times it can be appropriate to remove outlier data.
### Interpret logistic regression results
##### Evaluate a binomial logistic regression model
The metrics and graphs produced from a logistic regression model needs to be evaluated so as to know how good your model actually is. In binomial logistic regression, we're modelling the probability of a binary outcome. 
Having saved the data into training and hold out datasets;
```Python
# Split dataset into training and holdout datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```
next, you then save the logistic regression model as a variable `clf`;
```Python
clf = LogisticRegression().fit(X_train,y_train)
```
now input the holdout data into the `predict` method to get the predicted labels from the model. Save these predictions as a variable `y_pred`;
```Python
# Save predictions
y_pred = clf.predict(X_test)
```
Note that MLE or maximum likelihood estimation predicts the probability that an observation is zero or one. The `predict` function from `scikit-learn` actually labels each observation with a zero or one. It works by assuming a threshold of 0.5. So if MLE predicts a value greater than or equal to 0.5, the `predict` function will label that a one.  If MLE predicts a value less than 0.5, the `predict` function will label that a zero. We can print out the predicted labels by just calling on `clf.predict(X_test)`;
```Python
# Print out the predicted labels
clf.predict(X_test)
```
The `predict_proba` function on the other hand will allow you to check what probability was predicted for each data point;
```Python
# Print out the predicted probabilities
clf.predict_proba(X_test)[::,-1]
```
Now that you have predictions about whether each observation is a zero or one, you can create a confusion matrix that will give you a quick overview of how well your model categorized each data point in the holdout dataset.
A confusion matrix is a graphical representation of how accurate a classifier is at predicting the labels for a categorical variable. It displays how many data points were accurately categorized by a classifier for each category. The other squares in the grid convey how many data points were misclassified. Now lets build a confusion matrix using confusion matrix using `scikit-learn` modules;
```Python
# Import the metrics module from scikit-learn
import sklearn.metrics as metrics

# Calculate the values for each quadrant in the confusion matrix
cm = metrics.confusion_matrix(y_test, y_pred, labels = clf.classes_)

# Create the confusion matrix as a visualization
disp = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = clf.classes_)
```
In order to understand and interpret the numbers in the below confusion matrix, it is important to keep the following in mind:
* The upper-left quadrant displays the number of **true negatives**.
* The bottom-left quadrant displays the number of **false negatives**.
* The upper-right quadrant displays the number of **false positives**.
* The bottom-right quadrant displays the number of **true positives**.
![[Confusion matrix.png|400]]
A perfect model would yield all true negatives and true positives, and no false negatives or false positives.
##### Key metrics to assess logistic regression results
Confusion matrices help to visually represent and quantify how well a logistic regression performs. Here, we'll work through the Analyze and Construct phase of PACE and discuss evaluation metrics for logistic regression. These metrics summarize the true positives, true negatives, false positives and false negatives presented by the confusion matrix. The three metrics we'll discuss are precision, recall, and accuracy. Precision measures the proportion of positive predictions that were true positives. Precision is equal to $True Positives / (True Positives + False Positives)$.  The range of precision is 0-1. You can access these functions through scikit-learn metrics module;
```Python
# import the relevant libraries and modules
import sklearn.metrics as metrics
metrics.precision_score(y_test, y_pred)
```
Recall is the proportion of positives the model was able to identify correctly. Recall is equal to $True Positives / (True Positives + False Negatives)$. Recall ranges from 0-1. This is how we write it in python;
```Python
metrics.recall_score(y_test, y_pred)
```
Accuracy is the proportion of data points that were correctly categorized. Accuracy is equal to; $(True Positives + False Negatives) / Total Predictions$. Accuracy measures the proportion of outcomes our model correctly identifies as zero and the proportion of outcomes our model identifies as one. 
```Python
metrics.accuracy_score(y_test, y_pred)
```
Two other common evaluation techniques that maybe helpful when working with classifiers are the ROC curve and AUC. These concepts are related to the thresholds, true positives, and false positives. Although we use a threshold of 0.5 to generate our predictions, sometimes the threshold is determined based on the scenario. Notice that when we decrease the threshold, the true positive increases because we are predicting more observations to be positive, but the false positive rate also increases. The model's true positive rate and false positive rate changes at every threshold. 
With an ideal model there would exist a threshold where the true positive rate is high and the false positive rate is low. We can use an ROC curve in AUC to examine how the true positive and false positive rate changes together at every threshold.
Data professionals may use ROC curves and AUC when comparing classification models. Allow yourself some extra time and practice to understand how best to apply these measurement tools to support the stories you're telling with data.
##### Common logistic regression metrics in Python
Logistic regression is a powerful technique for categorical prediction tasks in data science. Data professionals often use metrics such as precision, recall, and accuracy, as well as visualizations such as ROC curves, to gauge the performance of their logistic regression models. 
It is important to evaluate the performance of a model, as this shows how well the model can make predictions. The results from applying metrics can be used to report how well a model performs to relevant stakeholders. In this reading, you will review parts of a confusion matrix.
###### Parts of a confusion matrix
A confusion matrix helps summarize the performance of a classifier. The components of a confusion matrix are used to compute metrics for evaluating logistic regression classifiers. The four key parts of a confusion matrix, in the context of a binary classification are the following:
- True negatives: The count of observations that a classifier predicted as False (0)
- True positives: The count of observations that a classifier correctly classified as True (1)
- False positives: The count of observations that a classifier incorrectly predicted as True (1)
- False negatives: The count of observations that a classifier incorrectly predicted as False (0)
These counts are useful in computing metrics such as precision, recall, accuracy, and ROC for evaluating logistic regression classifiers.
###### Precision
Precision measures the proportion of data points predicted as True that are actually True. Imagine that you have built a logistic regression classifier for email spam detection, trained this classifier on a relevant dataset, and used this classifier to generate predictions for a set of emails. The predictions consist of True and False values. True represents an email predicted as spam, and False represents an email predicted as not spam. The precision for this classifier would convey the proportion of emails that are actually spam, out of all the emails that have been predicted as spam.
###### Recall
Recall measures the proportion of data points that are predicted as True out of all the data points that are actually True. Imagine that you have built a logistic regression classifier for fraud detection and generated predictions. In the predictions, True represents a credit card transaction predicted as fraudulent, and False represents a credit card transaction predicted as not fraudulent. 
###### Accuracy
Accuracy measures the proportion of data points that are correctly classified. Imagine that you have built a logistic regression classifier for loan approval prediction. In the predictions, True represents a prediction that the loan will be approved, and False represents a prediction that the loan will not be approved. The accuracy score for this classifier would convey the proportion of loans that have been correctly classified.
###### ROC curves
An ROC curve helps in visualizing the performance of a logistic regression classifier. ROC stands for receiver operating characteristic curve. To visualize the performance of a classifier at different classification thresholds, you can graph an ROC curve. In the context of binary classification, a classification threshold is a cutoff for differentiating the positive class from the negative class.
An ROC curve plots two key concepts:
- True Positive Rate: equivalent to recall.
- False Positive Rate: The ratio between False Positives and the total count of observations that should be predicted as False. 
For each point on the curve, the X and Y coordinates represent the False Positive Rate and the True Positive Rate respectively at corresponding threshold.
![[ROC Curve.png|400]]
You can examine an ROC curve to observe how the False Positive Rate and True Positive Rate change together over the different thresholds. In the ROC curve for an ideal model, there would exist a threshold at which the True Positive Rate is high and the False Positive Rate is low. The more that the ROC curve hugs the top left corner of the plot, the better the model does at classifying the data.
###### AUC
AUC stands for area under the ROC curve. AUC provides an aggregate measure of performance across all possible classification thresholds. It ranges from 0.0 to 1.0. A model whose predictions are 100% wrong has an AUC of 0.0, and a model whose predictions are 100% correct has an AUC of 1.0. An AUC smaller than 0.5 indicates that the model performs worse than a random classifier (that is, a classifier that randomly assigns each example to True or False), an AUC larger than 0.5 indicates that the model performs better than a random classifier.
![[AUC.png|400]]
##### Interpret logistic regression models
Interpreting a logistic regression model involves examining coefficients and computing metrics. After you fit your logistic regression model to training data, you can access the coefficient estimates from the model using code in python. You can then use those values to understand how the model makes predictions. This reading will show you an example of how to interpret coefficients from a logistic regression model, as well as things to consider when choosing metrics for model evaluation.
###### Coefficients from the model
To understand how logistic regression works, its important to start with the equation that describes the relationship between variables. That equation is also called the logit function.
###### The logit function
When the logit function is written in terms of the independent variables, it conveys the following: there is a linear relationship between each independent variable, $X$, and the logit of the probability that the dependent variable, $Y$, equals 1. The logit of that probability is the logarithm of the odds of that probability.
The equation for the logit function in binomial logistic regression is shown below. This involves the probability that $Y$ equals 1, because 1 is the typical outcome of interest in binary classification, where the possible values of $Y$ are 1 and 0.
$logit(p) = log(p/(1-p) = B_o + B_1 X_1$ where $p=P(Y = 1)$
###### Interpret coefficients
Imagine you have built a binomial logistic regression model for predicting emails as spam or non-spam. The dependent variable, $Y$, is whether an email is spam(1) or non-spam(0). The independent variable, $X_1$, is the message length. Assume that `clf` is the classifier you fitted to training data. You can use the following code to access the coefficient $B_1$ estimated by the model:
```Python
clf.coef_
```
If the estimated $B_1$ is 0.186, for example, that means a one-unit increase in message length is associated with a 0.186 increase in the log odds of $p$. To interpret change in odds of $Y$ as a percentage, you can exponentiate $B_1$, as follows.
	$e^{B_1} = e^{0.186} = 1.204$
So, for every one-unit increase in message length, you can expect that the odds the email is spam increases by 1.204, or 20.4%.
###### Things to consider when choosing metrics
The next important step after examining the coefficients from a logistic regression model is evaluating the model through metrics. The most commonly used metrics include precision, recall, and accuracy. The following sections describe things to keep in mind when choosing between these.
###### When to use precision
Using precision as an evaluation metric is especially helpful in contexts where the cost of a false positive is quite high and much higher than the cost of a false negative. For example, in the context of email spam detection, a false positive (predicting a non-spam email as spam) would be more costly than a false negative (predicting a spam email as non-spam). A non-spam email that is misclassified could contain important information, such as project status updates from a vendor to a client or assignment deadline announcements from an instructor to a class of students.
###### When to use recall
Using recall as an evaluation metric is especially helpful in contexts where the cost of a false negative is quite high and much higher than the cost of a false positive. For example, in the context of fraud detection among credit card transactions, a false negative (predicting a fraudulent credit card charge as non-fraudulent) would be more costly than a false positive (predicting a non-fraudulent credit card charge as fraudulent).A fraudulent credit card charge that is misclassified could lead to the customer losing money, undetected.
###### When to use accuracy
It is helpful to use accuracy as an evaluation metric when you specifically want to know how much of the data at hand has been correctly categorized by the classifier. Another scenario to consider: accuracy is an appropriate metric to use when the data is balanced, in other words, when the data has a roughly equal number of positive examples and negative examples. Otherwise, accuracy can be biased. 
For example, imagine that 95% of a dataset contains positive examples, and the remaining 5% contain negative examples. Then you train a logistic regression classifier on this data and use classifier to predict on this data. If you get an accuracy of 95%, that does not necessarily indicate that this classifier is effective. Since there is a much larger proportion of positive examples than negative examples, the classifier may be biased towards the majority class (positive) and thus the accuracy metric in this context may not be meaningful. When the data you are working with is imbalanced, consider either transforming it to be balanced or using a different evaluation metric other than accuracy.
Key takeaways
- Examine the beta coefficients from a model to understand how the model predicts the dependent variable.
- When determining which metrics are meaningful for evaluating a logistic classifier, consider the context of the data involved, how the predictions will be useful, and how impactful False Positives versus False Negatives are in that context.
##### Answer questions with regression models
Here, we'll focus on the kinds of questions you might encounter in your work as a data professional. Some of these techniques used include logistic regression models, linear regression models, and hypothesis testing. The PACE framework, Plan, Analyze, Construct, and Execute helps guide your work. 
The Plan phase helps you understand which needs are being prioritized based on the questions being asked and the data you have access to and, determining which models or tests would be most appropriate. 
###### An example includes: 
Imagine you are a data professional at a recording studio. You have a team meeting and the conversation is about the number of times each song is streamed. Some questions that come up include: What factors influence the number of music streams? How much does each factor influence the number of streams?
Since the number of music streams is the outcome variable and the number of streams is a continuous variable, you could consider linear regression or hypothesis testing. But because the question ask about how much each factor influences music streams, linear regression is a better model to answer the question. 
Remember that linear regression allows for accessible interpretation of the coefficients and R-squared to help explain which factors impact the outcome variable and by how much. But you want to make sure that the model assumptions are met to add validity to your conclusions and insights. 
###### Lets consider another example. 
Imagine you're working for a cafe. They are sampling different coffee beans from different countries and want to figure out which kind of coffee beans sell better. The team has put together some projections about how they expect the beans to sell. But they are curious if these bean sales are independent of their pastry sales. The country of origin of beans is a known differentiator. The pastry sales would be more of the covariate. 
In this case, although the outcome variable, sales, is still continuous, the focus of the question is about comparing different groups, such as different kinds of coffee beans and different countries of origin. Therefore, you should focus more on hypothesis testing, which can be a great way to conduct A/B tests. The $H_0$ would be that the cafe sells approximately the same number of bags of each coffee bean type. The $H_a$ would be that the cafe does not sell the same number of bags of each coffee bean type. By conducting a series of tests, you can either accept or reject the $H_0$ with a particular P-value to help understand how well the model explains the trends. The team will be able to better understand which beans to order to sell more coffee at the cafe. 
###### One last example
You are working for a social media company and you're interested in exploring why some posts do or do not go viral. You decide on a question: How can I predict whether a post will go viral? Since the outcome variable is binary, either the post go viral or does not. Binomial logistic regression might be the first model you consider.
The best way to determine if a logistic regression is the right choice is to build and evaluate the model. There are many metrics you can use including P-value, confusion matrices, precision, recall, accuracy, ROC/AUC, AIC, and BIC. Choosing the best metric will depend on the coefficients for logistic regression models; remember to exponentiate them.
Recall that when sharing results, logistic regression coefficients report in percentages how much a factor increases or decreases the likelihood of an outcome. As a data professional, you will encounter many different questions that require a variety of approaches to address. By focusing on the fundamentals of what each model does well, you'll be able to find ways to put these tools into practice.
##### Prediction with different types of regression
Key linear regression techniques you'll encounter in your work as a data professional include linear regression, hypothesis testing, and logistic regression. When your goal is to make predictions with data, it is important to consider these different approaches and think about which approach will best help you achieve your task. Here, you'll learn more about how to choose the most relevant regression technique for a project, based on the question you want to answer, the outcome variable, and how it is measured.
###### How to choose a regression technique
When choosing a regression technique, it is important to consider the data you are working with and the question you want to address. Things to consider:
1. What is the question you want to answer? In other words, what do you want to predict?
2. Which variable in the data can be the outcome variable (dependent variable or Y)?
3. How is the outcome variable (dependent variable or Y) measured? If the outcome variable is continuous, it is more likely that either linear regression or hypothesis testing will be most appropriate. However, if the outcome variable is binary, you will find logistic regression to be more useful.
Definition of terms for context: 
- A dependent variable (Y) is the variable a given model estimates, also referred to as a response or outcome variable.
- An independent variable (X) is a variable that explains trends in the dependent variable, also referred to as an explanatory variable or predictor variable.
###### Example contexts for regression
The following examples demonstrate how the questions about prediction, outcome variable, and measurement can be navigated in order to choose a regression technique.
###### Example context: User engagement
In your work as a data professional, imagine that you are interested in making predictions about user engagement for a mobile app.
First, you might ask, what is the question you want to answer?
One possible question could be ' How much does each in-app feature influence user engagement?'. The in-app features might include a live chat with customer support, an FAQ section that updates weekly, and a community space to connect with other users. Next, you might ask, which variable in your data can be the outcome variable? If you have access to data about users' session lengths (in other words, how long users spend in the app each time they open it), the outcome variable can be session length. Your next question might be: how is the outcome variable measured? Session length can be measured by the number of minutes, which is continuous. Because the outcome variable is continuous, and you are interested in how much each feature influences the outcome variable, you could proceed with linear regression and check the relevant model assumptions. If there is only one feature of interest, you would build a simple linear regression model. If there are multiple features of interest, you would build a multiple linear regression model.
Another question of interest could be 'Does a dynamic landing page versus a static page make a difference in user engagement?' The outcome variable can be session length, measured by the number of minutes, for this example, too. Since the outcome variable is continuous, and the target question is about whether there is a difference in user engagement when one type of landing page is used over the other, you could proceed with hypothesis testing. You can then frame the hypothesis, which could be the following:
- $H_0$ : Users spend approximately the same amount of time in the app when landing page is dynamic versus when it is static.
- $H_a$ : Users DO NOT spend approximately the same amount of time in the app when the landing page is dynamic versus when it is static.
Another question you might be interested in 'Will a user engage with the new line of products in-app?' Next, you might ask, which variable in your data can be the outcome variable? If you have access to data about whether a user clicks to view the new line of products, that could be the outcome variable. The next question is: how is the outcome variable measured? Whether a user clicks to view that content can be represented as a binary variable, with 1 indicating the clicked to view content and 0 indicating that they did not click to view that content. Since this outcome variable is binary, you could proceed with binomial logistic regression.
###### Example context: Patient response
Now imagine that you are tasked with making predictions about patient responses to medical treatments. 
You can start by asking , what is the question you want to answer?
A possible question could be "How much does each factor influence a patient's response to a medical treatment?" If the goal of the treatment is to improve white blood cell (WBC) count and you have access to that data, WBC count can be the outcome variable. The outcome variable is a continuous measure, and you could use linear regression to address this task.
Another question of interest could be "Will Treatment A, Treatment B, or Treatment C have a stronger impact on a patient's WBC count?" The outcome variable in this case would also be WBC count, which is continuous. Since the target question is about comparing different treatments, it would be best to proceed with hypothesis testing. You can then form the hypotheses, which could be the following:
- $H_0$ : Patients have approximately the same white blood cell count with each treatment.
- $H_a$ : Patients do NOT have approximately the same white blood cell count with each treatment.
A different question you might be interested in: "With Treatment A, will a patient's WBC count reach the ideal range?" If you have access to the associated data, the outcome variable would be whether a patient's WBC count reaches the ideal range or not, which is a binary variable: 1 indicating that their WBC count falls within the ideal range and 0 indicating that it does not. You could build a logistic regression model to make predictions in this scenario.
###### Key takeaways
- Consider the question you want to answer and the data you have access to when choosing a regression technique for making predictions.
- Identifying the outcome variable of interest and how it is measured will help you decide which regression technique is most suitable for your task.
