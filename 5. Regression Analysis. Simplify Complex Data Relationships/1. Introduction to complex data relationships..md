You'll begin by exploring the main steps for building regression models, from identifying your assumptions to interpreting your results. Next, you'll explore the two main types of regression: linear and logistic. You'll learn how data professionals use linear and logistic regression to approach different kinds of business problems.
##### Introduction to course 5
We'll be discussing regression models and more hypothesis testing so that you can explore the relationships in your data. The tools we learn about will help you to uncover powerful insights about your data, tell compelling stories and influence decisions and strategy making. The modelling fundamentals we explore will give you a stronger foundation for entry level jobs in the data career space and to tackle more advanced topics in the future, like machine learning.
We will be applying your skills to the first model: regressions. In this course, we will talk about modelling relationships between variables. 
To do this, we will focus on regression analysis or regression models. They are a group of statistical techniques that use existing data to estimate the relationship between a single dependent variable and one or more independent variables. 
The techniques learnt will help you answer any number of questions with actionable steps to achieve your organization's goals. For example, regression models can help you understand:
- what variables impact sales.
- the factors that lead a customer to subscribe to a newsletter.
- it can help you understand why a user keeps scrolling on a company's website.
We'll also discuss the role data professionals play in making responsible decisions, from data handling to modelling. No matter how good a potential data story is, how we arrive at our story is the priority in being honest and effective storytellers.
Python programming will be critical in running and testing complex models, visualizing data and communicating results. Rigorous EDA will inform which models we choose and how we approach the modeling process.
Statistics will play a major role in helping us understand how our models work and will allow us to present actionable results to stakeholders. It will help us build the models we talk about. Regression analysis is a relevant and marketable skill. Regression models are flexible so you can design them based on the data that you have. Additionally, regression model results offer opportunities for interpretation and communication. Data professionals can provide insights from these models that align clearly with actionable steps.
For example, we're able to build regression models to identify what actions on a website are indicative of high value customers. For instance, there is a high likelihood that customers who visit the sale page, watch a video or sign up for emails are customers who will make multiple purchases in a year. 
Some of these indicators may seem obvious but having a regression analysis that identifies and quantifies the relationship is powerful. We're able to use the information in marketing campaigns to attract new customers.
Together we'll be exploring regression analysis as the basis of a solid foundation for building more complex machine learning models. We'll explain how to determine if a model is appropriate for the data, how to run the model and how to understand the computer's results. We'll discuss the math and the concepts step by step the whole time.
###### Tiffany: Gain actionable insights with regression models
a Marketing Science Lead at Google. 
Building regression models to predict things like who is going to be a high-valued customer or how to best allocate budget across different campaigns. You'll be able to answer a wide variety of questions using different types of regression models. Also building regression models and trying to interpret the coefficients. 
For example:
- building a lot of regression models to identify things like who is a high-value customer or who's going to make multiple purchases in a year by analyzing website behavior. Here, we really want to get down to which pages or which actions that people are taking on a website that's indicative of them being a high-value customer or someone who makes multiple purchases within an year.
- working with a client who wanted to know how to optimize their millions of dollars of marketing budget across different channels, and by building a regression model, we are able to help them optimize their spend in order to increase sales.
Some problems that are arising are; the end of third-party cookies. Third-party cookies in application are those found in ads that follow you around the internet. With those going away, we have a brand-new opportunity to come up with different model types and different analyses to try to do things that we are easily able to identify previously using third-party cookies in that tracking system, and so there is a massive opportunity for innovation right now in the analytics field and marketing.
There is a lot of information out here right now, just keep an open mindset and learn.
##### Welcome to module 1
Learn how data professionals go from a problem to actionable insights using regression analysis techniques. The focus for regression analysis is about understanding relationships between variables. 
- We'll use the PACE framework; Plan, Analyze, Construct, and Execute and its application to simple linear regression.
- Regression analysis
- Simple linear regression
- Multiple linear regression
- Hypothesis testing
- Logistic regression
##### PACE in regression analysis
Models used in the data career space are a family of techniques that rely on existing information or data points to inform what we might think other data points will look like. The goal is always to tell a story about the relationships between the variables in the data. The story will help the stakeholders adjust their business strategy and decisions.
Modelling follows an iterative process. You may be familiar with other frameworks, such as data life cycle or the six steps of EDA. Here, we will cover each step of the modelling process using PACE. It stands for Plan, Analyze, Construct, and Execute. It provides us with the foundation for conducting regression analysis.
How does PACE work in the context of regression analysis? Let's review that:
- The Plan stage
In regression modeling, the plan stage is about understanding your data in the problem context. Knowledge you bring, whether from industry or other fields, can be instrumental here. 
Contextualize and understand the data and the problem. By considering what data you have access to, how the data was collected, and what the business needs are, you'll be able to strategically analyze, construct, and execute the rest of your work. The Plan stage will guide the other three stages of PACE. After you plan, you have to analyze.
- The Analyze stage
In this stage, you examine your data more closely so you can choose a model or a couple of models you think might be appropriate. When working with regression analysis, this is where you use Python to perform EDA and check the model assumptions as needed.
Model assumptions are statements about the data that must be true to justify the use of a particular data techniques. 
A good understanding of statistics gives data professionals the power to construct meaningful models. After you analyze, you must construct.
- The Construct stage
For regression analysis, this is where you actually build a model in Python or your coding language of choice. This step involves selecting variables, transforming the data as needed, and writing code. Recheck model assumptions after you build the model. The last part is evaluating the model results. At this point, you are answering the questions, how good is my model? You'll choose  metrics, compare models, and get preliminary results. Then based on your evaluation, you can use EDA to refine your model accordingly.
As a data professional, you must be an honest storyteller. Studying the results produced by the regression will uncover relationships within your data and help you discover insights to tell the full story. This leads to the part of PACE, 
- The Execute stage
You'll interpret everything you learned from analyzing and constructing to share the story. You'll prepare formal results and viz and share them with stakeholders. To do this, you'll convert model statistics into statements describing the relationship between the variables in the data.
These descriptions must consider the context and initial questions from the Plan phase. 

At the center of everything is data. The PACE framework is iterative, and helps data professionals stay organized. The insights data professionals produce must be data-driven and accurate and they have to make sense given the business or community contexts. Your experience as a data professional will help you decide when to pivot between the stages of PACE. 
##### Linear regression
Regression analysis is about estimating relationships between a single dependent variable and one or more independent variables. Here we'll discuss a modelling technique called linear regression.
Many patterns that you've observed in daily life can be expressed using linear regression models. For example:
- as a version of a computer software gets older, online searches for that software version may decrease.
- as a social media personality gains followers, their book sales increase.
These relationships can be modelled using a linear regression. This type of relationship is visualized on a graph as a line. A line is a collection of infinite number of points extending in two opposite directions. In a graph, the individual points show up as a line, and we only see a portion of the line.
Linear regression is a technique that estimates the linear relationship between a continuous dependent variable y and one or more independent variables x. For example, we could model the relationship between the prices of a product and the number of sales. Our y variable would be the number of sales and our x variable would be prices. 
Linear regression models allows us to estimate continuous dependent variables. Continuous variables are variables that can take on any real value between its minimum and maximum value. For example, product sales, vehicle speed, and time spent on a webpage are all continuous variables. While linear regression allows us as data professionals to estimate continuous dependent variables, there are other regression models that let us estimate categorical variables. Categorical variables have a finite number of possible values. For example, types of products and educational level are examples of categorical variables.
We'll also talk about dependent and independent variables. The dependent variable is the variable a given model estimates. Its sometimes called a response or outcome variable and is commonly represented with the letter y. We assume that the dependent variable tends to vary based on the values of independent variables, typically represented by an x. Independent variables are also referred to as explanatory variables or predictor variables.
For example, let's say you are working at a cake shop and you're trying to understand the factors that contribute to cake sales. The dependent or y variable would be the number of cake slices sold on any given day. An independent or x variable could be how many cups of coffee are sold that day. Maybe as more coffee is purchased, more cake is also purchased. 
In linear regression, you might encounter two more terms, slope and intercept. The slope refers to the amount we expect y, the dependent variable , to increase or decrease per one unit increase of x, the independent variable.
- Going back to the example, the slope would be how many slices of cake are purchased per cup of coffee purchase. 
The intercept is the value of y, the dependent variable when x, the independent variable equals 0. 
- Going back to the cake example, the intercept would be the number of cake slices that are sold when zero cups of coffee are sold. 
There are two kinds of correlation, positive and negative. Positive correlation is a relationship between two variables that tend to increase or decrease together. For example, as more cups of coffee are purchased, more cake slices are purchased. Negative correlation, on the other hand, is an inverse relationship between two variables. When one variable increases, the other variable tends to decrease. The reverse is true too. For example, lets say you're still working at the cake shop and you're estimating how often to refill the iced coffee dispenser. You can model the relationship between iced coffee and hot coffee sales. As hot coffee sales increase, you might notice iced coffee sales tend to decrease, or perhaps you are working for a media company and you're analyzing readership. As the length of the news article increases, the number of people that finish reading the article decrease. This is an example of negative correlation.
Identifying these kinds of relationships can be incredibly useful in the workplace and in everyday life. Determining linear relationships helps us answer questions such as;
- which factors are associated with an increase or decrease in product sales?
- which factors make social service providers increase resources in a given region?
- which factors lead to more or less demand for public transportation?
In the cases mentioned, how big the slope of the regression is, tells us how much sales, resource allocation, and public transportation increase or decrease. Using linear regression, you can help answer similar questions in any industry.
However, its important to note that correlation is not causation. For example in your cake shop, people buying coffee does not cause cake sales to increase. When modelling variable relationships, a data scientist must be mindful of the extent of their claims.
Causation describes a cause-and-effect relationship where one variable directly causes the other to change in a particular way. Proving causation statistically requires much more rigorous methods and data collection than correlation.
For a data professional, the distinction between correlation and causation is especially important when presenting results. For example, although we can say as someone gets older, the number of places they have visited tends to rise. We cannot necessarily say that someone's age causes them the number of places they had visited to increase. There could be other factors causing you to travel more that coincide with your aging, such as visiting family or travelling more for work. Any of these factors could be correlated to aging, but its hard to say whether age or other factors are causing the travelling. 
Articulating that correlation is not causation is part of a data professionals best practices and ethical toolbox. Both correlation and causal relationships provide useful insights. Regression analysis helps data analytics professionals tell nuanced stories without needing to prove causation. 
##### Mathematical linear regression
In an ideal world, you would want every data point relevant to the question you are trying to answer. This is called a population. 
Let's say you are working for a publishing company. You want to understand the relationship between an author's social media following, and their book sales. You would need data on every book author, social media follower count, and every book sale of all time. This is an impossible task, but luckily, you don't actually need an entire population to run meaningful regression analysis. You can get a reasonable estimate with a representative sample.
A sample is a part of the population, which is just the statistical way of saying, a sample is some of the data you could possibly have. If you have a set of sample data, each data point can be represented with its own set of attributes or x and y values.
In that case, the sample data does not contain all possible values from the population of data. The observed values or actual values, are the existing sample of data. Each data point in this sample is represented by an observed value of the dependent variable and an observed value of the independent variable.
In the publishing data example, the dependent variable y, is book sales, and the independent variable x, is how many followers the author has on social media. An observed value you might have in your dataset would be x or the number of followers equals to 10000, and y or number of books sales equals 500.
The goal of the regression analysis is to define a relationship mathematically between the sample y's and x's to understand how the two variables interact. You can imagine that at every x value, there are many possible values that y can take on. To simplify this understanding, linear regression focuses on the mean of y given a particular value of x. This mean is represented by a Greek symbol mu. In statistics, we write the intercepts as Beta 0 a.k.a. Beta naught, and the slope is written as Beta mu of y. The Betas are sometimes called parameters. Parameters are properties of populations and not samples. We can never know their true value since we can't observe the whole population. But we can calculate estimates of the parameters using our sample data. To differentiate between the population parameters and the estimates of the parameters, we denote the estimate with the hat symbol in the formula to represent parameter estimates. But in order to use a simplified notation; Y equals Beta 0 plus Beta 1 times X.
These estimated Betas are also called regression coefficients. Now, whenever you see the hat symbol, you'll know that you are estimating Betas, also known as regression coefficients. 
In the formula, the regression coefficients are the slope and intercept, they describe the linear relationship found in the sample data. 
But how do you arrive at those regression coefficients? One of the most common ways to calculate linear regression coefficients is ordinary least squares estimation, or OLS for short. Lets discuss how OLS works. In linear regression analysis, we as data professionals, are trying to minimize something called the loss function. The loss function is a function that measures the distance between the observed values and the models estimated values. Theoretically we could draw an infinite number of lines that model the data we have. But we don't want to find just any line. We want to find the best fit line. We want to minimize the loss function.

##### Introduction to logistic regression
In  single a coin toss, the chance that the coin will come up heads or tails is 0.5 or 50%. This is a classic probability problem. But in the field of data analytics, we get to use a technique called logistic regression to model much more complex probability problems. For example:
- what factors lead to someone subscribing or not subscribing to a newsletter?
- under what circumstances does someone comment on an online video or social media post?
- given certain factors, how likely is it that someone renews their membership to an organization?
All these questions are tackling discrete events or categorical data. There are a specific set of possible outcomes. Subscribe or don't subscribe, comment or don't comment, renew or don't renew. To answer these questions, data professionals use a model called logistic regression.
Logistic regression is a technique that models a categorical dependent variable based on one or more independent variables. The dependent variable can have two or more possible discrete values. 
Let's say that your company has a newsletter and is interested in increasing readership. On the company website users have the opportunity to subscribe to the newsletter. One factor related to the newsletter subscription could be how many minutes the user spends on the webpage before leaving. Our dependent variable y has two possibilities. Users don't subscribe, which we'll represent with a 0. Or users do subscribe, which we'll represent with a 1. Our independent variable x is continuous and measures how many minutes the users spend on the webpage before leaving.
When you plot this hypothetical data on a scatter plot like we would when doing EDA or exploratory data analysis, we can observe that the data points are roughly in two horizontal lines. The higher one indicates the user subscribed, this is when y equals 1. The lower one indicates that the user did not subscribe. This is when y is 0. The x axis indicates how long a user was on the site in minutes. 
Since the relationship between x and y is not just a straight line, we need a mathematical way of expressing the relationship between x and y. Logistic regression will allow us to model the probability a user will subscribe to the newsletter. The key concept is that the mean of y given x is equal to the probability of y equals one given x. 
In logistic regression, we use a link function to express the relationship between the x's and the probability that y equals some outcome. A link function is a non-linear function that connects or links the dependent variable to the independent variables mathematically. 
The differences between linear and logistic regression models. 
- Linear regression uses continuous data while logistic regression uses categorical data. Choosing one model over the other is about the kind of data you have. You can answer similar questions about what factors impact an outcome of interests.
- Since linear regression models a continuous variable, we're estimating the mean of y. But logistic regression models a categorical variable, so we are estimating the probability of an outcome. For example, if y equals 1 or if y equals 0.
- For linear regression, we can express y directly as a function of x. But for logistic regression, we need a link function to connect the probability of y with x.
There are types of logistic regression models:
- logistic regression with just two categories, like the subscription problem. Covered here.
- more complex versions of logistic regression that can model multiple outcomes or categories, such as types of skincare products people buy, or types of services that people receive.
Computers are incredibly powerful and enable us as data practitioners to focus less on the math and more on the storytelling.
