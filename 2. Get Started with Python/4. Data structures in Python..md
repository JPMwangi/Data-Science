Here, you'll explore fundamental data structures such as lists, tuples, dictionaries, sets, and arrays. Next you'll use NumPy and Pandas.
### Lists and tuples.
##### Data types and Data structures.
A data type is an attribute that describes a piece of data based on its values, its programming language or the operations it can perform. In Python this includes the classes, integers, strings, floats, and Boolean expressions etc. 
Data structures - Collections of data values or objects that contain different data types. They are used to store, access, organize and categorize their data with speed and efficiency. Knowing which data structures fit a specific task is a key part of data work and will help streamline your analysis. Therefore, data structures can contain data types. 
This is what data structures allow:
- More efficient storage, access and modification.
- Allow you to organize and categorize your data.
- Allow you to relate collections of data to each other and perform operations accordingly.
##### Lists.
A data structure that helps store and manipulate an ordered collection of items. They are similar to strings in that they allow duplicate elements, indexing and slicing, and also sequences of elements. 
Sequence - A positionally ordered collection of items. Strings are sequences of characters while lists stores sequences of elements of any type.
Mutability - The ability to change the internal state of a data structure. Example is lists are mutable. Their elements can be modified, added or removed.
Immutability - A data structure or element's values can never be altered or updated. Example is Strings are immutable.
You use an index when working with the elements of a list. An index provides the numbered position of an element in an ordered sequence.
Example of a list:
```python
x = ['Now', 'we', 'are', 'cooking', 'with', '7', 'ingredients.']

print(x[3]) # prints out cooking from the list. Indexing in Python starts at 0.

# slicing in lists.
x[3:5] # to get the 4th and 6th positions from the list.
x[:2] # to get the first 2 elements from the list.
x[2:] # to leave out some elements from the list.

# to check whether an element exists in a list. Use 'in' keyword.
'Now' in x # this will return a Boolean. 

# modifying a list.
# 1. append() -  adding an element to the end of a list. req. 1 argument.
x.append('Welcome')

# 2. insert(). req. 2 arguments. index/position to insert and what to insert.
x.insert(5, '8')

# 3. remove(). removes an element from the list. req. 1 parameter.
x.remove('ingredient')

# 4. pop(). removes an element from the list. at a given index.
x.pop(5)
```

##### Tuple.
An immutable sequence that can contain elements of any data type. 
They are useful when you want to access and reference data than to change and manipulate it. This is when you simply want to find some and data and keep it intact. They are like lists but cannot be changed as easily making them secure. They are helpful because they keep data that needs to be processed together in the same structure. 
```python
# instantiating a tuple using ()
fullname = ('Masha', 'Z', Hopper)

# adding a value to a tuple.
fullname = fullname + ('Jnr',) # this assigns a new value at the end of the tuple.

# creating a tuple using tuple() function.
fullname = ['Masha', 'Z', Hopper]
fullname = tuple(fullname) # this converts the fullname into a tuple.

# tuples are used to return values in a function.
def to_dollars_cents(price):
	'''
	Split price (float) into dollars and cents.
	'''
	dollars = int(price // 1)
	cents = round(price % 1 * 100*)
	return dollars, cents

# you can unpack a tuple.
dollars, cents = to_dollars_cents(6.55)
dollars + 1, cents + 1 # here we have unpacked the tuples. now you can modify them.
```
Advantages of using tuples:
	Makes your processes as a data professional more efficient.
	It saves memory by optimizing your memory too.
	When collaborating, use of tuples is interpreted as data that should not be modified.
#### List comprehension.
Formulaic creation of a new list based on the values in an existing list.
```python
# list comprehension.
pip_list = [domino[0] + domino[1] for domino in dominoes]
```
Its elegant and much faster to execute.
##### Dictionaries.
A data structure that consists of a collection of key-value pairs. They are used to analyze large datasets with vast processing power. This helps them gather and transform vast user information. 
```python
# instantiating dictionaries.
# 1. with {}.
zoo = {
	'pet_1' : 'penguins',
	'pet_2' : 'zebras',
	'pet_3' : 'lions',
	}

# 2. with dict() function.
zoo = dict(
	'pen_1' = 'penguins',
	'pet_2' = 'zebras',
	'pet_3' = 'lions',
	)

# assigning values to dictionaries.
zoo['pen_4'] = 'crocodiles'

# checking whether a key exists in the dictionary using 'in' arg. works with keys only.
'pen_1' in zoo # returns a Boolean.

```
Dictionary keys must be immutable. They may include, but are not limited to, integers, floats, tuples and strings. Mutable data types cannot be used as keys eg, lists, sets, and/or other dictionaries. Dictionaries are unordered and you can't access them using a positional index. Because of this, the order of their entry changes as you are working with them. 
```python
new_team = {}

for name, age, position in player:
	if position in new_team:
		new_team[position].append((name, age))
	else:
		new_team[position] = [(name, age)]

# useful methods to use on dictionaries to make use of their power.
# keys() method only lets you retrieve only the dictionary keys. As a list.
new_team.keys()

# values() method only lets you retrieve only the dictionary values. As a list of lists.
new_team.values()

# items() method only lets you retrieve both the dictionary keys and values.
for a, b in new_team.items():
	print(a, b)
```
##### Set.
A data structure in Python that contains only unordered, non-interchangeable elements. Each set element is unique and immutable, however, the set itself is mutable. They are valuable in storing mixed data in a single row or record in a data table. They are also useful when storing a lot of elements and you want to be certain that each element is only present once. Because of their immutable nature, they cannot be used as keys in a dictionary. A set cannot be indexed or sliced.
```python
# instantiate a set.
# 1. set() method. takes an iterable as an arg and returns a new set object.
set(['foo', 'bar', 'baz', 'foo']) # turn a list into a set.
set(('foo', 'bar', 'baz', 'foo')) # turn a tuple into a set.
set('foo') # turn a string into a set.

# 2. non-empty braces. pass an arg. empty {} are dictionaries.
x = {'foo'} # instantiating a set using braces. must pass in an argument in the braces.

# functions to use on sets.
# intersection() - finds an element that 2 sets have in common.
set_1 & set_2   # & operator.
set_1.intersection(set_2) # the .intersection()

# union() - finds all elements from both sets. this is a communicable operation.
set_1 | set_2   # | operator.
set_1.union(set_2) # the .union()

# difference() - finds elements present in one set, but not the other. not a communicable op
set_1.difference(set_2) # the .difference()
set_1 - set_2 # the - (minus/subtraction) operator. 

# symmetric_difference() - finds elements from both sets that are mutually not present in the other.
set_1.symmetric_difference(set_2) # the symmetric_difference()
set_1 ^ set_2 # the caret.
```
#### Arrays and vectors with NumPy.
##### Library and Packages.
Library or package - broadly refers to a reusable collection of code. It also contains relatable modules and documentation. Examples 
- matplotlib - a library for creating static, animated, and interactive visualizations in Python.
- Seaborn - a data viz library based on matplotlib that provides a simpler interface for working with common plots and graphs.
- NumPy - numerical python, an essential library that contains multidimensional array and matrix data structures and functions to manipulate them. Used for scientific computation.
- Pandas - a powerful library built on top of NumPy that's used to manipulate and analyze tabular data.
Module - a simple python file containing a collection of functions and global variable.
Global variable - variables that can be accessed from anywhere in a program or script.
Common modules used are math and random.
##### Introduction to NumPy.
An important package in Python is NumPy. It contains multidimensional array and matrix data structures as well as functions to manipulate them. Its power comes from vectorization. Vectorization enables operations to be performed on multiple components of a data object at the same time. This is particularly useful for data professionals because their jobs often involves working with very large quantities of data and vectorized code saves a lot of time because it computes more efficiently.
```python
# suppose we have a new list_a and list_b.
list_a = [1,2,3]
list_b = [2,4,6]

# and we want to create a new list_c that's the element-wise product of each list above.
list_c = [2,8,18]

# 1. write a for loop.
list = []
for i in range(len(list_a)):
	list_c.append(list_a[i] * list_b[i])
list_c

# 2. Use numpy to perform the above challenge in a vectorized computation.
import numpy as np

array_a = np.array(list_a)
array_b = np.array(list_b)

array_a * array_b
```
The vectorized approach is simpler, easier to read, and faster to execute. Because while loops iterate over one element at a time, vector operations compute simultaneously in a single statement. The efficiency of this is useful when working with large datasets, using less memory in the process. 
- Import statement - used to load an external library, package, module, or function into your computing environment.
N-dimensional array (ndarray) is the core data structure of NumPy.
```python
# creating an ndarray from a python object.
import numpy as np

# by passing the object to the np.array() function. 
x = np.array([1,2,3,4])
x

# ndarray objects are mutable, so you can change the values they contain.
x[-1] = 6 # we have changed the last element in the array x.

# to change the size of an array, you have to reassign it.
x[4] = 10 # this will throw an error.

# elements in array must be of the same data type.
arr = np.array([1, 2, 'coconut'])
arr # the following array will contain the same data type of 'string'.

# use dtype attribute to check the data type of an array.
arr.dtype # used to check the data type of the array.

# use shape attribute to check the shape of an array.
arr.shape

# use ndim attribute to check the number of dimensions of an array.
arr.ndim

# creating a 2 dim array from a list of lists.
arr_2d = np.array([1,2], [3,4], [5,6], [7,8]) # a 4 by 2 array

# use reshape method to change the shape of an array.
arr_2d = arr_2d.reshape(2,4) # changed a 4 by 2 array into a 2 by 4 array.
```

### Dataframes with pandas.
##### Introduction to pandas.
Built from NumPy. Its key functionality is the manipulation and analysis of tabular data. Tabular data is data in form of a table, with rows and columns. A spreadsheet is a common example of tabular data. Its easier to work with than NumPy which is abstract. Pandas provides a simple interface that allows you to display your data as rows and columns. Meaning that you can always follow exactly what's happening to your data, as you manipulate it. A dataframe is a core data structure of pandas. Its made up of rows and columns and can contain data of many different data types. 
```python
# init pandas library.
import pandas as pd

# reading data from a csv file.
x = pd.read_csv('input the path to the file here.') # a hypothetical dataset x.

# calculating mean of a column. Use the mean() method.
x['column'].mean()

# the same can be done for max(), min(), and std() methods.
x['column'].max()
x['column'].min()
x['column'].mstd()

# you can also check how many items are in each category.
x['category'].value_counts()

# checking summary statistics of an entire dataset requires only 1 line of code.
x.describe()

# pandas also allows one to filter based on simple or complex logic.
x[(x['age'] > 60) & (x['Pclass'] == 3)] # complex logic filter.

# you can add a column into a dataframe. 
x['2024_fare'] = x['fare'] * 146.14

# select rows and columns using indexing.
x.iloc[1][3] # selecting an item/name on row one, column three.

# doing more complex data groupings.
x.groupby(['sex', 'class']).agg({'fare': ['count', 'sum']})
fare['fare_avg'] = fare['fare']['sum'] / fare['fare']['count']
fare
```

##### pandas basics.
Core pandas object classes are DataFrame, and Series.
- DataFrame - a two-dimensional, labeled data structure with rows and columns. Think of it as a spreadsheet or a SQL table. It can contain many different kinds of data. Used by data professionals to analyze, manipulate and structure data in pandas. 
```python
# creating a dataframe.
import pandas as pd

data = {'col1': [1,2], 'col2': [2,4]} # df created from a dictionary. key=column name
df = pd.DataFrame(data=data)
df

# creating a df from a np array.
df2 = pd.DataFrame(np.array([1,2,3], [4,5,6], [7,8,9]), columns=['a', 'b', 'c'], index=['x', 'y', 'z'] )
df2

# importing a csv file.
c = pd.read_csv('cvs file path')
c.head() # reading the first five lines of data from the df.

# working with series objects
c.iloc[0] # a series object of row 1 of the df.

# selecting a row using its name.
c['name'] # accessing a row using its name.

# methods and attributes in pandas.
c.shape # shape of the df. attris
c.columns # to display the columns in a df.
c.info() # to get the summary of the df using info() method.

# commom pandas terminology of values.
NaN # reps. null values. stands for not a number.
object # returned when a Series has mixed data type. 
# accessing a single column name.
c['column'] # use this method 
c.column # or this method. when the column name doesn't have a space.

# to select multiple columns of a dataframe, which forms a dataframe.
d[['column1', 'column2']] # selected columns 1 & 2. returns a df object.

# selecting rows and columns by index. iloc[]. stands for integer-location.
c.iloc[0] # returns a Series object of 1 row of the df at that index.
c.iloc[[0]] # a list of a single int returns a df obj of a 1 row of the df @ that index.
c.iloc[0:3] # accessing a range of rows. The last row isn't returned.
c.iloc[0:3, [3,4]] # selecting a subset of rows and columns together.
c.iloc[:, [3]] # selecting a single column in its entirety.
c.iloc[0,3] # get a single value @ a particular row & column. 
c.iloc[1][3] # here we have selected data from column 1 row 3.

# selecting pandas rows and columns by name.
c.loc[1:3, ['name']] # selecting rows 1-3(their given index no.) at the 'name' column.
c.loc['name1':'name3', ['col_name']] # selecting rows by name @ column name.

# adding a new column to the dataframe.
c['new_col'] = c['age'] + 5

```
- CSV file - stands for 'comma separated values'. A plaintext file that uses commas to separate distinct values from one another.
- Series - is a one-dimensional, labeled array. Its a row in dataframe.

##### Boolean masking.
A filtering technique that overlays a Boolean grid onto a dataframe in order to select only the values in the dataframe that align with the True values of the grid.
```python
data = {
	'planet': ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune', ],
	'radius_km': [2440, 6052, 6371, 3390, 69911, 58232, 25362, 24622],
	'moons': [0, 0, 1, 2, 80, 89, 27, 14]
}

planets = pd.DataFrame(data) # here we have initialized the data into a df.

# boolean masking
mask = planets['moons'] > 20 # returns a boolean
planets[mask] # actual boolean mask.

# you can also apply boolean masking like this.
planets[planets['moons'] > 20] # here the code is self explanatory.

# logical operators using pandas.
mask2 = (planets['moons'] < 20) | (planets['moons'] > 50) # | = OR logical operator.
planets[mask2] # here we are applying boolean masking.

# using logical operators. ~ means must not have. 
mask3 = (planets['moons']>20) & ~(planets['moons']==80) & ~(planets['radius_km']<50000)
planets[mask3] # applying boolean masking. 
```
Applying a Boolean mask does not modify the actual dataset rather, it filters the dataset. However you can assign a variable to the results if you need to use the results again.
#### Grouping and aggregation.
###### groupby().
A pandas DataFrame method that groups rows of the dataframe together based on their values at one or more columns, which allows further analysis of the groups. 
```python
import numpy as np
import pandas as pd

data = {
	'planet': ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune', ],
	'radius_km': [2440, 6052, 6371, 3390, 69911, 58232, 25362, 24622],
	'moons': [0, 0, 1, 2, 80, 89, 27, 14],
	'type': ['terrestrial', 'terrestrial', 'terrestrial', 'terrestrial', 'gas giant', 'gas giant', 'ice giant', 'ice giant' ],
	'mean_temp': [167, 464, 15, -65, -110, -140, -195, -200],
	'magnetic_field': ['yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes']
}

planets = pd.DataFrame(data) # here we have initialized the data into a df.

planets.groupby(['type']) # here we create a groupby object stored in the computer's memory
planets.groupby(['type']).sum() # only numerical columns are returned.
planets.groupby(['type']).sum()[['moons']] # to select a specific column, pass a list.

# groupby on multiple columns.
planets.groupby(['type', 'magnetic_field']).mean() # only numerical columns are returned.
```
When learning or working with a new data tool, its important to begin by applying it to a small example. This will better enable you to understand exactly what's happening. 
###### aggregate.
agg() - short form. A pandas groupby method that allows you to apply multiple calculations to groups of data.
```python
planets.groupby(['type']).agg(['mean', 'median'])
planets.groupby(['type', 'magnetic_field']).agg(['mean', 'median'])

# passing functions as arguments in groupby.
def percentile_90(x):
	return x.quantile(0.9)

planets.groupby(['type', 'magnetic_field']).agg(['mean', percentile_90])
```
##### Merging and joining data.
The task of joining data to an existing dataframe. The concat() and merge(). 
###### - concat().
A pandas function that combines data either by adding it horizontally as new columns for existing rows, or vertically as new rows for existing columns. axis 1 means across rows and axis 0 means down columns. The two axis of a DataFrame are; *0* runs vertically over rows and *1* which runs horizontally over columns.
```python
import numpy as np
import pandas as pd


# we have 2 dataframes containing planets, and we want to join them.
data_1 = {
	'planet': ['Mercury', 'Venus', 'Earth', 'Mars'],
	'radius_km': [69911, 58232, 25362, 24622],
	'moons': [0, 0, 1, 2]
}

df1 = pd.DataFrame(data)

data = {
	'planet': ['Jupiter', 'Saturn', 'Uranus', 'Neptune', ],
	'radius_km': [69911, 58232, 25362, 24622],
	'moons': [80, 83, 27, 14]
}

df2 = pd.DataFrame(data)

# to concatenate dataset 1 with dataset 2.
df3 = pd.concat([df1, df2], axis=0) # add data vertically by extending axis 0.
df3 = df3.reset_index(drop=True) # to keep 1 index column.
```
###### - merge().
A pandas function that joins two dataframes together; it only combines data by extending along axis 1 horizontally. How does data joins work? For two datasets to connect, they need to share a common point of reference. A 'key' which is the shared points of reference between different dataframes --what to match on. Ways to join: 
- inner join - Where only the keys that are in both dataframes gets included in the merge.
- outer join - Where all the keys from both dataframes gets included in the merge.
- left join - Where all the keys in the left dataframe are included even when they are not in the right dataframe.
- right join - Where all the keys in the right dataframe are included even when they are not in the left dataframe.
```python
df4 = {
	'planet': ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune'],
	'magnetic_field': ['yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes']
}

# inner join
inner_join = pd.merge(df3, df4, on='planet', how='inner') 

# outer join
outer_join = pd.merge(df3, df4, on='planet', how='outer')

# left join
left_join = pd.merge(df3, df4, on='planet', how='left') 

# right join
right_join = pd.merge(df3, df4, on='planet', how='right')
```