Data professionals use smaller samples of data to draw conclusions about large datasets. You'll also learn:
- about the different methods they use to collect and analyze sample data and 
- how they avoid sampling bias.
- learn how sampling distributions can help you make accurate estimates.
### Introduction to sampling
###### Welcome to module 3
Sampling - the process of selecting a subset of data from a population. For example, if you want to survey a population of 100,000 people, you can select a representative sample of 100 people. Then you can draw conclusions about the population based on your sample data. 
To learn:
- how sampling process works.
- how data professionals use sample data to better understand larger populations.
- inferential statistics and the concept of representative sample.
- different stages of sampling process from choosing target population to collecting data for your sample.
- two main types of sampling methods - probability and non-probability sampling.
- benefits and drawbacks of various sampling methods.
- random sampling.
- different forms of bias and sampling like under coverage and non-response bias and how they can affect non-probability sampling methods.
- sampling distributions which are probability distributions for sample statistics.
- sampling distributions for both sample means and proportions and how to estimate the corresponding values for populations.
- central limit theorem and how it can help you estimate the population mean for different types of datasets.
- use of Python SciPy stats module to work with sampling distributions and make a point estimate of the population mean.
###### Cliff: Value everyone's contribution
Strategy for communication when working with partners and stakeholders:
- Set up low-stakes meetings just to understand what their broader business goals are. Don't even think about the specific project you're working on, but more broadly; how do they define success? This will help you to understand where the work that you're doing fits into the context of their bigger picture. 
- Repeat back what someone said. Repeat it back to them, whether it's your understanding of their question or the output that they're trying to see from the data, just to test if you actually really understand their goals.
- Lay out a set of options and discuss (from a data perspective). This is when you are working with somebody and you feel that you're not getting to the root of the problem. Engage in a conversation around which of these options resonate for them.
- Find a balance between listening and telling as a way to unlock some of the data they might not have thought about themselves.
###### Introduction to sampling
There are two types of stats:
- Descriptive stats which are stats that summarize the main features of a dataset.
- Inferential stats which are stats that use sample data to draw conclusions about a larger population. 
Here, we're returning to inferential stats and explore the relationship between sample and population in detail. Including, how data professionals use sampling in data science and importance of working with the sample that is representative of the population. 
Sampling is the process of drawing a subset of data from a population. Data professionals use it to answer many different types of questions. Example of questions that sampling helps answer:
- How many products in an app store do we need to test to feel confident that all the products are secure from malware?
- How do we select a sample of users to run an effective A/B test for an online retail store?
- How do we select a sample of customers of a video streaming service to get reliable feedback on the shows they watch?
The questions above are focused on the method of selection of a sample from a population. A population is the total number of elements that you want to study. They can be items, people, or products. Sampling is useful in data science because:
- requires less time than collecting data on every item from the population.
- using a sample saves money and resources.
- using a sample is more practical than analyzing an entire population especially in modern data analytics where one deals with extremely large datasets.
For example: Let's say you want to know the percentage of people in a large city who uses laptop computer. Ways of doing the survey is:
- Surveying every resident in the city. First, it would be difficult to access contact information for every resident of the city. Second, giving a survey to every resident of the city would be expensive, complicated and time consuming.
- Another way, is to find a much smaller subset of residents and give them a survey. This subset is your sample, then you can use the sample data you collected about laptop use to draw conclusions about laptop use of the entire population. Collecting a sample is faster, more practical and less expensive than collecting data on every member of the population.
Your sample should be representative of your population. A representative sample accurately reflects the characteristics of a population. The inferences and predictions you make are based on your sample data. If your sample is not representative of the population, then your inferences will not be reliable and your predictions will not be accurate. And this can lead to negative outcomes for stakeholders and organizations. For example: Let's say that you only contact computer scientists for your laptop survey. Your sample will not accurately reflect the overall population. Computer scientists are much more likely to use a laptop computer than the typical city resident. Many residents may not have access to any kind of computer or even know how to use one. The sample used in this case is not representative for a representative sample would include people with different levels of computer knowledge and access.
A good model cannot overcome a bad sample. Its important as a data professional to always use a representative sample.
Data professionals work with powerful statistical tools that can model complex datasets and help generate valuable insights. But if the sample you are working with does not accurately reflect your population (not representative), then it ultimately does not matter how good your model is. If your predictive model is based on a bad sample, then your predictions will not be accurate.
Ultimately, the quality of your sample helps determine the quality of the insights you share with stakeholders. To make reliable inferences about all your customers based on feedback from a sample of customers, make sure your sample is representative of the population.
###### The relationship between sample and population.
Inferential statistics use sample data to draw conclusions or make predictions about a larger population. Data professionals use inferential statistics to gain valuable insights about their data. Here you'll learn: the relationship between sample and population in more detail. How data professionals use sampling in data work. the importance of working with a sample that is representative of the population.
Population and sample
In stats, a population includes every single possible element that you are interested in measuring, or the entire dataset that you want to draw conclusions about. A statistical population can refer to any type of data, including: People, organizations, objects, events, and more. 
For instance, a population might be the set of:
- all students at a university
- all the cell phones ever manufactured by a company
- all the forests on Earth
A sample is a subset of a population. Samples drawn from the above populations might be:
- the math majors at the university
- the cell phones manufactured by the company in the last week
- the forests in Kenya
Data professionals use samples to make inferences about populations. In other words, they use the data they collect from a small part of the population to draw conclusions about the population as a whole. 
![[sample-population diagram.png|450]]
Sampling
This is the process of selecting a subset of data from a population. 
In practice, it's often difficult to collect data on every member or element of an entire population. A population my be very large, geographically spread out, or otherwise difficult to access. Instead, you can use sample data to draw conclusions, make estimates, or test hypotheses about the population as a whole. Data professionals use sampling because:
- Its often impossible or impractical to collect data on the whole population due to size, complexity, or lack of accessibility.
- It's easier, faster, and more efficient to collect data from a sample.
- Using a sample saves money and resources.
- Storing, organizing, and analyzing smaller datasets is usually easier, faster, and more reliable than dealing with extremely large datasets.
Example: election poll
Imagine you're a data professional working in a country with a large population like India, Indonesia, the U.S, or Brazil. There's an upcoming national election for president. You want to conduct an election poll to see which candidate voters prefer. Let's say the population of eligible voters is 100 million people. To survey 100 million people on their voting preferences would take an enormous amount of time, money, and resources --even assuming it would be possible to locate and contact all voters, and that all voters would be willing to participate.
However, it is realistic to survey a sample of 100 or 1000 voters drawn from the larger population of all voters. When you are dealing with a large population, sampling can help you make valid inferences about the population as a whole.
Representative sample
To make valid inferences or accurate predictions about a population, your sample should be representative of the population as a whole. Recall that a representative sample accurately reflects the characteristics of a population. The inferences and predictions you make about your population are based on your sample data. If your sample doesn't accurately reflect your population, then your inferences will not be reliable, and your predictions will not be accurate. And this can lead to negative outcomes for stakeholders and organizations.
Statistical methods such as probability sampling help ensure your sample is representative by collecting random samples from the various groups within a population. These methods help reduce sampling bias and increase the validity of your results.
Example: election poll.
Ideally, the sample for your election poll will accurately reflect the characteristics of the overall voter population. A voter population in a large country will be diverse in political perspectives, geographic location, age, gender, race, education level, socioeconomic status, etc. 
Your sample will not be representative if you only collect data from people who belong to certain groups and not others. For example, if you survey people from one political party, or who have advanced degrees, or are older than 70. The results of an election poll based on non-representative sample will not be accurate.
In general, any claims or inferences you make about any population will have more validity if they are based on a representative sample.
Data professionals work with powerful statistical tools that can model complex datasets and help generate valuable insights. But if the sample you are working with does not accurately reflect your population (not representative), then it ultimately does not matter how good your model is. If your predictive model is based on a bad sample, then your predictions will not be accurate.
Ultimately, the quality of your sample helps determine the quality of the insights you share with stakeholders. To make reliable inferences about a population, make sure your sample is representative of the population.
###### The sampling process
As a data professional, you'll work with samples all the time. Its important to know how the sampling process works because it directly affects the quality of your sample data. The sampling process helps determine whether your sample is representative of the population and whether your sample is unbiased. Here, we'll go through the main stages of the typical sampling process. This will give you a useful framework for understanding how sampling is conducted and how the sampling process can affect your sample data.
To get an idea of the sampling process, lets divide it into five steps:
- identify target population
The complete set of elements that you're interested in knowing more about.
- select the sampling frame
A list of all the items in your target population. Basically, its the list of everything you're interested in researching. Its specific, unlike a population which is general. It may not match your target population because you may not have access to every member of the population. Your sampling frame will not exactly overlap with your target population. So the sampling frame is the accessible part of your target population. 
- choose the sampling method
This is to ensure your sample is representative. There are two main types of sampling methods: probability sampling (uses random selection to generate a sample) and non-probability sampling (based on convenience or personal preference). 
- determine the sampling size
This refers to the number of individuals or items chosen for a study or experiment. 
- collect the sample data
Conduct a survey.
Effective sampling ensures that your sample data is representative of your target population. Then, when you use sample data to make inferences about the population, you can be reasonably confident that your inferences are reliable. The decisions you make at each step of the sampling process can affect the quality of your sample data. Understanding the sampling process will make you a better data professional, whether you're analyzing data collected by other researchers or conducting a survey on your own.
###### The stages of the sampling process
As a data professional, you'll work with samples all the time. This will be collected by your team, or previously collected by other researchers. Its important to know how this process works, because it helps determine whether your sample is representative of the population, and whether your sample is unbiased.
The sampling process.
First, let's review the main steps of the sampling process:
- Identify the target population.
- Select the sampling frame.
- Choose the sampling method.
- Determine the sample size.
- Collect the sample data.
Let's explore each step in more detail with an example. Imagine you're a data professional working for a company that manufactures home appliances. The company wants to find out how customers feel about the innovative digital features on their newest refrigerator model. The refrigerator has been on the market for 2 years and 10,000 people have purchased it. Your manager asks you to conduct a customer satisfaction survey and share the results with stakeholders.
Step 1: Identify the target population.
The first step in the sampling process is defining your target population. The target population is the complete set of elements that you're interested in knowing more about. Depending on the context of your research, your population may include individuals, organizations, objects, events, or any other type of data you want to investigate. The context of your research can guide you in knowing what your target population is.
A well-defined population reduces the probability of including participants who do not fit the precise scope of your research. For example, you don't want to include all the company's customers, or customers who purchased the company's other refrigerator models.
In this case, your target population will be the 10,000 customers who purchased the company's newest refrigerator model. These are the customers you want to survey to learn about their experience with the newest model.

Step 2: Select the sampling frame.
The next step is to create a sampling frame. This is a list of all the individuals or items in your target population. 
The difference between a target population and a sampling frame is that the population is general and the frame is specific. So if your target population is all the customers who purchased the refrigerator, your sampling frame could be an alphabetic list of the names of all these customers. The customers in your sample will be selected from this list.
Ideally, your sampling frame should include the entire target population. However, for practical reasons, your sampling frame may not exactly match your target population, because you may not have access to every member of the population. For instance, the company's customer database may be incomplete, or contain data processing errors. Or, some customers may have changed their contact information since their purchase, and you may be unable to locate or contact them. Furthermore, sometimes the sampling frame might include elements outside of the target population simply by accident or because it is impossible to know the target population with certainty.
Therefore, generally your sampling frame is the accessible part of your target population, but sometimes it will include elements apart from this set.

Step 3: Choose the sampling method.
The third step in the sampling process is choosing a sampling method.
There are two main types of sampling methods: Probability sampling and non-probability sampling. Probability sampling uses random selection to generate a sample. Non-probability sampling is often based on convenience, or the personal preferences of the researcher, rather than random selection. Often, probability sampling methods require more time and resources than non-probability sampling methods.
Ideally, your sample will be representative of the population. To help ensure this, choose the right sampling method. Because probability sampling methods are based on random selection, every element in the population has an equal chance of being included in the sample. This gives you the best chance to get a representative sample, as your results are more likely to accurately reflect the overall population.
So, assuming you have the budget, the resources, and the time, you should use a probability sampling method for your survey.

Step 4: Determine the sample size.
Step four of the sampling process is to determine the best size for your sample, since you don't have the resources to survey everyone in your sampling frame. In stats, sample size refers to the number of individuals or items chosen for a study or experiment.
Sample size helps you determine the precision of the predictions you make about the population. In general, the larger the sample size, the more precise your predictions. However, using larger samples typically requires more resources.
The sample size you choose depends on various factors, including the sampling method, the size and complexity of the target population, the limits of your resources, your timeline, and the goals of your research.
Based on these factors, you can decide how many customers to include in your sample.

Step 5: Collect the sample data.
Now, you're ready to collect your sample data, which is the final step in the sampling process.
You give a customer satisfaction survey to the customers selected for your sample. The survey responses provide useful data on how customers feel about the digital features of the refrigerator. Then, you share your results with stakeholders to help them make more informed decisions about whether to continue to invest in these features for future versions of this refrigerator, and develop similar features for other models.

Key takeaways
Effective sampling ensures that your sample data is representative of your population. Then, when you use sample data to make inferences about the population, you can be reasonably confident that your inferences are reliable.
The decisions you make at each step of the sampling process can affect the quality of your sample data. Understanding the sampling process will make you a better data professional, whether you are analyzing data collected by other researchers or conducting a survey on your own.
###### Compare sampling methods
There are 4 different probability sampling methods:
- Simple random sampling
Here, every member of a population is selected randomly and has an equal chance of being chosen. How? By using a random number generator or by another method of random selection. Benefits are; there is fair representation in the sample since every member of the population has an equal chance of being chosen. Random samples tend to avoid bias and surveys like these give you more accurate results. However, in practice, its often expensive and time-consuming to conduct large, simple random samples. If your sample is not large enough, a specific group of people in the population may be underrepresented in your sample. Using a larger sample size will more accurately reflect the population. 
- Stratified random sampling
Here, you divide a population into groups and randomly select some members from each group to be in the sample. These groups are called strata. Strata can be organized by age, gender, income, or whatever category you're interested in studying. It helps ensure that members from each group in the population are included in the survey. This method allows you to draw more accurate conclusions about the relevant groups.  One main disadvantage of stratified sampling is that it can be difficult to identify appropriate strata (the relevance of categories in your study) for a study if you lack knowledge of a population.
- Cluster random sampling
Here, you divide a population into clusters, randomly select certain clusters, and include all members from the chosen clusters in the sample. Its similar to stratified random sampling, but in stratified random sampling, you randomly choose some members for each group to be in the sample. In cluster sampling, you choose all members from a group to be in the sample. Clusters are divided using identifying details, such as age, gender, location, or whatever you want to study. An advantage of this method is that it gets every member from a particular cluster, which is useful when each cluster reflects the population as a whole. This method is helpful when dealing with large and diverse populations that have clearly defined subgroups. A disadvantage of cluster sampling is that it may be difficult to create clusters that accurately reflect the overall population.  
- Systematic random sampling
Here, you put every member of the population into an ordered sequence. Then you choose a random starting point in the sequence and select members for your sample at regular intervals. Samples here are representative of the population since every member has an equal chance of being included in the sample. It can be quick and convenient when you have a complete list of the members of your population. A disadvantage is that you need to know the size of the population before you begin. If you don't have this information, its difficult to choose consistent intervals.
###### The impact of bias in sampling
Data professionals often use sample data to help them build machine learning models. Machine learning models today are used to determine who gets a loan or job interview, or an accurate medical diagnosis. Models based on representative samples are much more likely to make fair and unbiased decisions about who gets a loan or a job interview.
Using samples that are representative of the different types of people in the population helps ensure that each person receives the treatment that is best for them. Unfortunately, bias can affect sample data. 
Sampling bias occurs when a sample is not representative of the population as a whole. To eliminate bias, try to use samples that are representative of the overall population. There can be serious consequences for trying to draw conclusions from a biased sample. 
The four methods of non-probability sampling
- Convenience sampling
Choose members of a population that are easy to contact or reach. It involves collecting a sample from somewhere convenient to you such as your workplace, a local school, or a public park. Convenience sampling often show undercoverage bias which is when some members of a population are inadequately represented in the sample. 
- Voluntary response sampling
Consists of members of a population who volunteer to participate in a study. They tend to suffer from non-response bias. This is when certain groups of people are less likely to provide responses. People who voluntarily respond will tend to have stronger opinions, either positive or negative than the rest of the population.  This makes the volunteers a unrepresentative sample.
- Snowball sampling
Researchers recruit initial participants to be in a study and then ask them to recruit other people to participate in the study. The sample size gets bigger as more participants gets in. This type of recruiting can lead to sampling bias. Because initial participants recruit additional participants on their own, its likely that most of them will share similar characteristics which might be unrepresentative of the total population under study.
- Purposive sampling
Here, researchers select participants based on the purpose of their study. Applicants who do not fit the profile are rejected. In purposive sampling, the researcher often intentionally exclude certain groups from the sample to focus on a specific group they think is most relevant to their study. This could lead to biased outcomes because the sample is not representative of the overall population.
As a data professional, you have to think about bias and fairness the moment you start collecting sample 
data to the time you present your conclusions. Once you become aware of some common forms of bias, you can remain on the alert for bias in any form.
### Sampling distributions
###### How sampling affects your data
As a data professional, you'll work with sample data to make informed predictions about future sales revenue or product performance. Understanding how sampling affects your data both positively and negatively, will be important in your future career in data analytics. For instance, one-way data professionals use sample statistics is to estimate population parameters. 
A statistic is a characteristic of the sample and a parameter is a characteristic of the population. For example, the mean weight of a random weight of 100 penguins is a statistic. The mean weight of the total population of 10,000 penguins is a parameter. 
A data professional might use the mean weight of 100 penguins to estimate the mean weight of the population. This type of estimate is called a point estimate. A point estimate uses a single value to estimate a population parameter.
To learn :
- concept of sampling distribution and how it can help you represent the possible outcomes of a random sample.
- how the sampling distribution of the sample mean can help you make a point estimate of the population mean.
A sampling distribution is a probability distribution of a sample statistic. A probability distribution represents the possible outcomes of a random variable, such as a coin toss or die roll. In the same way, a sampling distribution represents the possible outcomes for a sample statistic, like the mean. 
Imagine you take repeated simple random samples of the same size from a population. Since each sample is random, the mean will vary from sample to sample in a way that cannot be predicted with certainty. Sampling variability refers to how much an estimate varies between samples. 
You can use a sampling distribution to represent the frequency of all your different sample means. It helps to visualize these samples as a histogram. The most frequently occurring sample means will be around the center while the least frequent sample means will be to the edges. As you increase the size of a sample, the mean weight of your sample data will get closer to the mean of the population. If you sample the entire population, in other words, if actually weighted all 10,000 penguins, your sample mean would be the same as your population mean. But to get an accurate estimate of the population mean, you don't have to weigh 10,000 penguins.
If you take a large enough sample size from a population, say 100 penguins, your sample mean will be an accurate estimate of the population mean. This is based on the Central limit theorem. You can also use your sampling in it to estimate how accurately the mean weight of any given sample represents the population mean weight. This is useful to know because the mean varies from sample to sample. In any given sample is not necessarily an exact reflection of the population mean. 
The more variability in your sample data, the less likely it is that the sample mean is an accurate estimate of the population mean. Data professionals use the standard deviation of the sample to means to measure this variability. Standard deviation measure the variability of your data or how spread out your data values are. The more spread between the data values, the larger the standard deviation. 
In stats, the standard deviation of the sample statistic is called the standard error. The standard error of the mean measures variability among all your sample means. A larger standard error indicates that the sample means are more spread out, whether there's more variability. A smaller standard error indicates that the sample means are closer together, or that there's less variability. The less the standard error, the more likely it is that your sample mean is an accurate estimate of the population mean.
Note that the concept of standard error is based on the practice of repeated sampling. In reality, researchers usually work with a single sample. Its often too complicated, expensive, or time-consuming to take repeated samples of a population. Instead, statisticians have derived a formula for calculating the standard error based on the mathematical assumption of repeated sampling. 
The formula for calculating the standard error of the sample mean: S/✔️n. S divided by the square root of n, where S is the sample standard deviation and n is the sample size. 
For example, in your study of penguins weights, imagine that a sample of 100 penguins has a mean weight of 3 pounds and a standard deviation of 1 pound. You can calculate the standard error by dividing the sample standard deviation 1 by the square root of the sample size of 100, which is 0.1. This means that your best estimate for the true population mean weight of all penguins is 3 pounds, but you should expect that the mean weight from one sample to the next will vary with a standard deviation of about 0.1 pounds. 
As your sample size gets larger, your standard error gets smaller. This is because standard error measures the difference between your sample mean and the actual population mean. As your sample gets larger, your sample mean gets closer to the actual population mean. The more accurate the estimate of the population mean, the smaller the standard error.
In general, you can have more confidence in your estimates as the sample size gets larger and the standard error gets smaller. This is because the mean of your sampling distribution gets closer to the population mean.
###### The central limit theorem
Data professionals use the central limit theorem to estimate population parameters for data in economics, science, business, and other fields. The central limit theorem can be used to estimate:
- The mean annual household income for an entire city or county.
- The mean height and weight for an entire animal or plant population.
- The mean commute time for all the employees of a large corporation.
To learn:
- More about the central limit theorem.
- How it can help you estimate the population mean for different types of data.
The central limit theorem states that the sampling distribution of the mean approaches a normal distribution as the sample size increases. In other words, as your sample increases, your sampling distribution assumes the shape of a bell curve. And if you take a large enough sample of the population, the sample mean will be roughly equal to the population mean.
For example, say you want to estimate the average height for a university student in South Africa. Instead of measuring millions of students, you can get data on a representative sample of the students. If your sample size is large enough, the mean height of your sample will be roughly equal to the mean height of the population.
There's no exact rule for how large a sample size needs to be in order for the central limit theorem to apply. In general, a sample size of 30 or more is considered sufficient. EDA can help you determine how large of a sample is necessary for a given dataset. What's really powerful about the central limit theorem is that it holds true for any population. You don't need to know the shape of your population distribution in advance to apply the theorem. If you collect a large enough sample, the shape of your sampling distribution will follow a normal distribution. This pattern is true even if your population has a skewed distribution.
In practice, the specific sample size you choose will depend on factors like budget, time, resources, and the desired level of confidence for your estimate. If you take a large enough sample from the population, the mean of your sampling distribution will equal the population mean. From this sample of the population, you can accurately estimate a parameter from the entire population. The central limit theorem is a useful method for better understanding the distribution of your data.
###### Infer population parameters with the central limit theorem
The central limit theorem states that the sampling distribution of the mean approaches a normal distribution as the sample size increases. In other words, as your sample size increases, your sampling distribution assumes the shape of a bell curve. And, as you sample more observations from a population, the sample mean gets closer to the population mean. If you take a large enough sample of the population, the sample mean will be roughly equal to the population mean.
For example, imagine you want to estimate the average weight of a certain class of vehicle, like light-duty pickup trucks. Instead of weighing millions of pickup trucks, you can get data on a representative sample of pickup trucks. If your sample size is large enough, the mean weight of your sample will be roughly equal to the mean weight of the population. (adhering to the law of large numbers).
Note: The central limit theorem holds true for any population. You don't need to know the shape of your population distribution in advance to apply them--the distribution could be bell shaped, skewed, or have another shape. If you collect enough samples of sufficient size, the shape of the distribution of their means will follow a normal distribution.
Conditions
In order to apply the central limit theorem, the following conditions must be set:
- Randomization: Your sample data must be the result of random selection. Random selection means that every member has an equal chance of being chosen for the sample. 
- Independence: Your sample values must be independent of each other. Independence means that the value of one observation does not affect the value of another observation. Typically, if you know that the individuals or items in your dataset were selected randomly, you can also assume independence. 
- 10%: To help ensure that the condition of independence is met, your sample size should be no larger than 10% of the total population when the sample is drawn without replacement (which is usually the case).
Note: In general, you can sample with or without replacement. When a population element can be selected only one time, you're sampling without replacement. When a population element can be selected more than one time, you are sampling with replacement. 
- Sample size: The sample size needs to be sufficiently large.
Let's discuss the sample size conditions in more detail. There is no exact rule for how large a sample size needs to be in order for the central limit theorem to apply. The answer depends on the following factors:
- Requirement for precision. The larger the sample size, the more closely your sampling distribution will resemble a normal distribution, and the more precise your estimate of the population mean will be.
- The shape of the population. If your population distribution is roughly bell-shaped and already resembles a normal distribution, the sampling distribution of the sample mean will be close to a normal distribution even with a small sample size.
In general, many statisticians and data professionals consider a sample size of 30 to be sufficient when the population distribution is roughly bell-shaped, or approximately normal. However, if the original population is not normal--for example, if it's extremely skewed or has lots of outliers--data professionals often prefer the sample size to be a bit larger. EDA can help you determine how large of a sample size is necessary for a given dataset.
###### The sampling distribution of the proportion
Data professionals also use sampling distributions to estimate population proportions. In stats, a population proportion refers to the percentage of individuals or elements in a population that share a certain characteristic. Proportions measure percentages or parts of a whole. For example, you might survey 100 employees at a large company to estimate what percentage of all employees like the food at the office cafeteria.
Data professionals might also use the sampling distribution of the proportion to estimate the proportion of all visitors to a website who make a purchase before leaving. Assembly line products that meet quality control standards, or voters who support a candidate in an upcoming election. To learn:
- sampling distribution of the sample proportion.
- how it can help you estimate the population proportion.
Sampling variability for the sample means or how the value of the mean varies from one sample to the next also holds true for proportions. You can use a sampling distribution to represent the frequency of all your different sample proportions. You can also show the sampling distribution of the proportion in a histogram. 
As with the sample means, the central limit theory also applies to sample proportions. As your sample size increases, the distribution of the sample proportion will be approximately normal. The overall average, or mean proportion, is located in the center of the curve. 
As with sample mean, you can use the standard error of the proportion to measure sampling variability. This tells you how much a particular sample proportion is likely to differ from the true population proportion. This is useful to know because the proportion varies from sample to sample, and any given sample proportion probably won't be exactly equal to the true population proportion. The more variability in your sample data, the less likely it is that the sample proportion is an accurate estimate of the population proportion.
Its important to understand the accuracy of your estimate because stakeholder decisions are often based on the estimates you provide. You can use a formula to calculate the standard error of the proportion. Which is the square root of p hat open parentheses, one minus p hat, close the parentheses. Where p hat refers to the population proportion, and n refers to the sample size.
As your sample size gets larger, your standard error gets smaller. Because the standard error measures the difference between your sample proportion and the true population proportion. As your sample gets larger, your sample proportion gets closer to the true population proportion. The more accurate the estimate of the population proportion, the smaller the standard error. Your estimate will help stakeholders make decisions. 
Typically, the next step for a data professional would be to use the standard error to construct a confidence interval. This describes the uncertainty of your estimate and gives your stakeholders more detailed information about your results. This helps you to more accurately predict preferences of a population.
###### The sampling distribution of the mean
Data professionals use sample statistics to estimate population parameters. For example, a data professional might estimate the mean time customers spend on a retail website, or the mean salary of the people who work in the entertainment industry. To learn:
- The concept of sampling distribution,
- how it can help you represent the possible outcomes of a random sample,
- how the sampling distribution of the mean can help you estimate the population mean.
Sampling distribution of the sample mean.
A sampling distribution is a probability distribution of a sample statistic. Recall that a probability distribution represents the possible outcomes of a random variable, such as a coin toss, or a die roll. In the same way, a sampling distribution represents the possible outcomes for a sample statistic. Sample statistics are based on randomly sampled data, and their outcomes cannot be predicted with certainty. You can use a sampling distribution to represent statistics such as the mean, median, standard deviation, range, and more.
Typically, data professionals compute sample statistics like the mean to estimate the corresponding population parameters.
Suppose you want to estimate the mean of a population, like the mean height of a group of humans, animals, or plants. A good way to think about the concept of sampling distribution is to imagine you take repeated samples from the population, each with the same sample size and compute the mean for each of these samples. Due to sampling variability, the sample mean will vary from sample to sample in a way that cannot be predicted with certainty. The distribution of all your sample means is essentially the sampling distribution. You can display the distribution of sample means on a histogram. Statisticians call this the sampling distribution of the mean.
Note: In practice, due to limited time and resources, data professionals typically collect a single sample and calculate the mean of that sample to estimate the population mean. Let's explore an example to get a more concrete idea of the sampling distribution of the mean.
Example: Mean length of lake trout
You are a data professional working with a team of environmental scientists. Your team studies the effects of water pollution on fish species. Currently, your team is researching the effects of pollution on the trout population in Lake Superior, one of the Great Lakes in North America. As part of this research, they ask you to estimate the mean length of a trout. Let's say there are 10 million trout in the lake. Instead of collecting and measuring millions of trout, you take a sample data from the population.
Let's say you take repeated simple random samples of 100 trout each from the population. In other words, you randomly choose 100 trout from the lake, measure them, and then repeat this process with a different set of 100 trout. For your first sample of 100 trout, you find that the mean length is 20.2 inches. For the second sample, the mean length is 20.2 inches. For the third sample, the mean length is 19.7 inches. And so on. Due to sampling variability, the mean length will vary randomly from sample to sample.
For the purpose of this example, let's assume that the true mean length of a trout in this population is 20 inches. Although, in practice, you wouldn't know this unless you measured every single trout in the lake. 
Each time you take a sample of 100 trout, it's likely that the mean length of the trout in your sample will be close to the population mean of 20 inches, but not exactly 20 inches. Every once in a while you may get a sample full of shorter than average trout, with a mean length of 16 inches or less. Or, you might get a sample full of longer than average trout, with a mean length of 24 inches or more.
You can use a sampling distribution to represent the frequency of all your different sample means. For example, if you take 10 simple random samples of 10 trout each from the population, you can show the sampling distribution of the mean as a histogram. The most frequency occurring value in your sample will be around 20 inches. The value that occurs least frequently will be the more extreme lengths, such as 16 inches or 24 inches.
As you increase the size of a sample, the mean length of your sample data will get closer to the mean length of the population. If you sampled the entire population--in other words, if you actually measured every single trout in the lake--your sample mean would be the same as the population mean.
However, you don't need to measure millions of fish to get an accurate estimate of the population mean. If you take a large enough sample size--say 1000 trout -- your sample mean will be a precise estimate of the population mean (20 inches).
Standard error
You can also use your sample data to estimate how precisely the mean length of any given sample represents the population mean. This is useful to know because the sample mean, and any given sample mean is likely to differ from the true population mean. For example, the mean length of any sample of trout might be 20.2 inches, 19.7 inches, and so on.
Data professionals use the standard deviation of the sample means to measure this variability. In stats, the standard deviation of the sample statistic is called the standard error. It provides a numerical measure of sampling variability. The standard error of the mean measures variability among all your sample means. A larger standard error indicates that the sample means are more spread out, or there's more variability. A smaller standard error indicates that the sample means are closer together, or that there's less variability.
In practice, using a single sample of observations, you can apply a formula to calculate the standard error of the sample mean. s/square root of n. S refers to the sample standard deviation, and n refers to the sample size.
For example, if your study of trout lengths, imagine that a sample of 100 trout has a mean length of 20 inches and a standard deviation of 2 inches. You can calculate the estimated standard error which is equal to 0.2.
This means you should expect that the mean length from one sample to the next will vary with a standard deviation of about 0.2 inches. 
The standard error helps you understand the precision of your estimate. In general, you can have more confidence in your estimates as the sample size gets larger and the standard error gets smaller. This is because, as your sample size gets larger, the sample mean gets closer to the population mean.
Key takeaways
Estimating population parameters through sampling is a powerful form of statistical inference. Sampling distributions describe the uncertainty associated with a sample statistic, and help you make proper statistical inferences. This is important because stakeholder decisions are often based on the estimates you provide.