You'll learn the basic rules for calculating probability for single events.
How data professionals use methods such as Bayes' Theorem to describe more complex events.
How probability distributions such as the binomial, Poisson, and normal distribution can help you better understand the structure of data.
### The basic concepts of probability
##### Welcome to Module 2
Probability is the branch of mathematics that deals with measuring and quantifying uncertainty. That is, probability uses math to describe the probability of something happening. For example, the chance of rain tomorrow, or of winning a lottery. Data professionals use probability to help business leaders make data driven decisions in situations of uncertainty.
No one can know the outcome of future events with complete certainty. What data professionals can do is use all the available data to make reasonable predictions based on probability. 
- Types of probability - objective and subjective.
- Basic rules of probability.
- Conditional probability.
- Bayes' Theorem.
- Probability distributions.
- Discrete probability distributions.
- Continuous probability distributions.
- Z-scores.
- SciPy stats module application.
###### Objective versus subjective probability.
Probability helps you measure and quantify uncertainty and make informed decisions about uncertain outcomes. Probability use cases:
- A company will sell a certain amount of product in a given time period.
- A financial investment will have a positive return.
- A political candidate will win an election.
- A medical test will be accurate.
##### Types of probability
###### Objective probability 
Is based on statistics, experiments, and mathematical measurements. This is used by data professionals. There are two types of objective probability: 
- Classical probability 
It's based on formal reasoning about events with equally likely outcomes. But most events are more complex and do not have equally likely outcomes. 
- Empirical 
Used by data professionals to describe more complex events without having equally likely outcomes. Its based on experimental or historical data. It represents the likelihood of an event occurring based on previous results of a past experiment or past events. 
Inferential stats use probability too. Data professionals rely on empirical probability to help them make accurate predictions based on sample data. For example, an A/B test lets you make a reasonable prediction about future users based on empirical probability. This probability can help an online business make smarter decisions and increase sales.
###### Subjective probability 
Is based on personal feelings, experience, or judgement. This type of probability does not involve formal calculations, statistical analysis, or scientific experiments. For example, you may have an overwhelming feeling that a certain horse will win a horse race, or your favorite team will win the championship game. You may have good reasons for your belief, but your reasons are personal or subjective. Your belief is not based on based on statistical analysis or scientific experiments. For this reason, the subjective probability of an event may differ widely from person to person.
Predictions made this way may not be reliable. Data science based on statistical analysis or objective probability can help accurately predict the potential impact of an outcome and help you make informed, data-driven decision about adopting the technology. 
##### The principles of probability
The probability that an event will occur is expressed as a number between 0 or 1.
- If the probability of an event equals 0, there is 0% chance that the event will occur.
- If the probability of an event equals 1, there is 100% chance that the event will occur.
There are lots of possibilities between 0 and 1. 
- If the probability of an event is 0.5, then there is a 50% chance that the event will or will not occur.
- If the probability of an event is close to 0, there is a small chance that the event will occur.
- If the probability of an event is close to 1, there is a strong chance that the event will occur.
Probability measures the likelihood of random events. The results of a random events cannot be predicted with certainty. Before flipping a coin and rolling a die, you do not know the outcome. The coin could show heads or tails, and a die could show any number one through six. These are examples of what statisticians call a random experiments, also known as statistical experiment.
Random experiment - Is a process whose outcome cannot be predicted with certainty. 
Characteristics of random experiments:
- The experiment can have more than one possible outcome.
- You can represent each possible outcome in advance.
- The outcome of the experiment depends on chance.
##### Fundamental concepts of probability
The three concepts at the foundation of probability theory:
Random event
Outcome
Event
Probability deals with random experiments, also known as statistical experiments. A random experiment is a process whose outcome cannot be predicted with certainty. In stats, the results of a random experiment is called an outcome. For example, if you roll a die, there are 6 possible outcomes. 
An event is a set of one or more outcomes. Using the example of a rolling die an event might be rolling an even number. This consists of the outcomes 2, 4, 6. Or the event of rolling an odd number consists of the outcomes 1, 3, 5.
In a random experiment, an event is assigned a probability.
###### The probability of an event
The probability that an event will occur is expressed as a number between 0 and 1. Probability may also be expressed as a percent. Knowing the probability of an event can help you make informed decisions in situations of uncertainty. 
###### Calculate the probability of an event
To calculate the probability of an event in which all possible outcomes are equally likely, you divide the number of desired outcomes by the total number of possible outcomes. 
###### Probability notation
Its often used to symbolize concepts in educational and technical contexts. In notation, the letter P indicates the probability of an event. The letters A and B represents individual events. For example, if you're dealing with two events, you can label one event A and the other event B.
- The probability of event A is written as P(A).
- The probability of event B is written as P(B).
- The probability of event A not happening is written as P(A').
- For any event A, 0<= P<=1. In other words, the P(A) is always between 0 and 1.
- If P(A) > P(B), then event A has a higher chance of occurring than event B.
- If P(A) = P(B), then event A and event B are equally likely to occur.
Key takeaways
Data professionals use probability to help stakeholders make informed decisions about uncertain events. Your knowledge of fundamental concepts of probability will be useful as a building block for more complex calculations of probability.
##### The basic rules of probability and events
In real life, you'll deal with probability of both single events and situations involving more than one event. Three basic rules of probability are : 
- Complement rule
In stats, the complement of an event is the event not occurring. For example, whether it rains or it does not rain (the complement of rain). P(A') = 1 - P(A). Apply to events that are mutually exclusive.
- Addition rule
Applies to events that are mutually exclusive.
The probability of an event happening and the probability of an event not happening must equal to one. P(A) + P(A') = 1. Addition rule for mutually exclusive events says that  P(A or B) = P(A) + P(B).
Mutually exclusive events cannot occur at the same time.  For example, you cannot visit Argentina and China at the same time or turn left and right at the same time.
- Multiplication rule
Applies to independent events. 
Multiplication rule for independent events says that P(A and B) = P(A) * P(B)
Independent events - Two events are independent if the occurrence of one event does not change the probability of the other event. This means that one event does not affect the outcome of the other event. For example, checking out a book from your local library does not affect tomorrow's weather. These events are separate and independent. 
These rules will help you better understand the probability of multiple events. Types of events: Mutually exclusive events, and Independent events.
###### The probability of multiple events
Many situations, both in daily life and data work, involve more than one event. As a future data professional, you'll often deal with probability of multiple events. 
###### Two types of events
The three basic rules in probability apply to different types of events. Both the complement rule and the addition rule apply to events that are mutually exclusive. The multiplication rule applies to independent events.
###### Mutually exclusive events
Two events are mutually exclusive if they cannot occur at the same time. 
###### Independent events
Two events are independent if the occurrence of one event doesn't change the probability of the other event. This means that one event does not affect the outcome of the other event. This means that the events are separate and independent.
###### Three basic rules
- Complement rule.
- Addition rule.
- Multiplication rule.
Key takeaways
The basic rules of probability help you describe events that are mutually exclusive or independent. Understanding basic rules of probability is an essential foundation for more complex analyses you will perform as a future data professional.
### Conditional probability
##### Conditional probability for dependent events
Conditional probability refers to the probability of an event occurring given that another event has already occurred. It allows you to describe the relationship between dependent events, or how the occurrence of the first event affects the likelihood of the second event. 
Conditional probability applies to two or more dependent events.
###### Dependent events
Two events are dependent if the occurrence of one event changes the probability of the other event. This means that the first event affects the outcome of the second event. For instance, if you want to get a good grade on an exam, you first need to study the course material. Getting a good grade depends on studying. If you want to eat at a popular restaurant without waiting for a table, you have to arrive early. Avoiding a wait depends on arriving early. In each instance, you can say that the second event is dependent on, or conditional on, the first event.
###### Formula for conditional probability
For two dependent events A and B, the probability of event A and event B occurring equals the probability of event A occurring, multiplied by the probability of event B occurring, given event A has already occurred.
P(A and B) = P(A) * P(B|A)
In probability, the vertical bar '|' indicates dependence, or that the occurrence of event B depends on the occurrence of event A. You can say this as 'the probability of B given A'.
The formula can also be expressed as:
P(B|A) = P(A and B) / P(A)
These are just two ways of representing the same equation. Depending on the situation, or what information you are given up front, it may be easier to use one or the other.
Note: The conditional probability formula also applies to independent events. When A and B are independent events:
P(B|A) = P(B)
So, the formula becomes:
P(A and B) = P(A) * P(B)
###### Key takeaways
Conditional probability helps you describe the relationship between dependent events. It is used by data professionals in a business context. For example, they might use conditional probability to predict how an event like a new ad campaign will impact sales revenue. This helps stakeholders make intelligent decisions about the best way to invest their company's resources. 
##### Bayes' Theorem
Is a math formula for determining conditional probability. The theory is named after Thomas Bayes, an 18th-century mathematician from London, England. Recall that conditional probability refers to the probability of an event occurring given that another event has already occurred. For example, when you draw an ace from a deck of playing cards, this changes the probability of drawing a second ace from the same deck.
Bayes' theorem provides a way to update the probability of an event based on new information about an event.
###### Posterior and prior probability
In Bayesian statistics, prior probability refers to the probability of an event before new data is collected. Posterior probability is the updated probability of an event based on new data. Bayes' theorem lets you calculate posterior probability by updating the prior probability based on your data. 
For example, let's say a medical condition is related to age. You can use Bayes' theorem to more accurately determine the probability that a person has the condition based on their age. The prior probability would be the probability of a person having the condition . The posterior, or updated probability would be the probability of a person having the condition if they are in a certain age group.
###### The theorem
Let's examine the theorem itself.
Bayes' theorem states that for any two events A and B, the probability of A given B equals the probability of A multiplied by the probability of B given A divided by the probability of B.
P(A|B) = P(B|A) * P(A) / P(B)
P(A) is the prior probability
P(A|B) is what you're trying to calculate or posterior probability.
Sometimes, statisticians and data professionals use the term 'likelihood' to refer to the probability of event B given event A, and the term 'evidence' to refer to the probability of event B.
P(B|A) = likelihood
P(B) = Evidence
Using these terms, you can restate Bayes' theorem as:
Posterior = Likelihood * Prior / Evidence
Thinking this way might help you to map your problem onto the equation. 
On way to think about Bayes' theorem is that it lets you transform a prior belief, P(A), into a posterior probability, P(A|B), using new data. The new data are the likelihood, P(B|A), and the evidence, P(B).
For now, a key point to remember is that Bayes' theorem includes both the conditional probability of B given A and the conditional probability of A given B. If you know one of these probabilities, Bayes' theorem can help you determine the other.
###### Example: spam filter
A well known application of Bayes' theorem in the digital world is spam filtering, or predicting whether an email is spam or not. In practice, a sophisticated spam filter deals with many different variables, including content of the email, its title, whether it has an attachment, the domain type (.edu or .org), and more. However, we can use a simplified version of a Bayesian spam filter for our example.
Let's say you want to determine the probability that an email is spam given a specific word appears in the email. For this example, let's use the word 'money'.
You discover the following information:
- The probability of an email being spam is 20%.
- The probability that the word 'money' appears in an email is 15%.
- The probability that the word 'money' appears in a spam email is 40%.
In this example:
- Your prior probability or P(A), is the probability of an email being spam. 
- Your posterior probability P(A|B), or what you ultimately want to find out, is the probability that an email is spam given that it contains the word 'money'.
The new data you will use to update your prior probability is the probability that the word 'money' appears in an email and the probability that the word 'money' appears in spam email. When you work with Bayes' theorem, its helpful to first figure out what event A is and what event B is -- this makes it easier to understand the relationship between events and use the formula.
Let's call event A a spam email and event B the appearance of the word 'money' in an email. Now, you can re-write Bayes' theorem using the word 'spam' for event A and the word 'money' for event B.
	P(A|B) = P(B|A) * P(A) / P(B)
	P(Spam |Money) = P(Money |Spam) * P(Spam) / P(Money): the probability that an email is spam given that the word 'money' appears in the email. 
Now, enter your data into the formula:
	P(Spam), or prior probability: the probability of an email being spam = 0.2, or 20%.
	P(Money), or evidence: the probability that the word 'money' appears in an email = 0.15, or 15%.
	P(Money| Spam), or likelihood: the probability that the word 'money' appears in an email given that the email is spam = 0.40, or 40%.
P(Spam | Money) = P(Money | Spam) * P(Spam) / P(Money) = 0.4 * 0.2 / 0.15 = 0.5333 or 53.3%
So the probability that an email is spam given that the email contains the word 'money' is 53.3%.
Key takeaways
Bayes' theorem is the foundation for the field of Bayesian inference, which is a powerful method for analyzing and interpreting data in modern data analytics. Data professionals use Bayes' theorem in a wide variety of fields, from artificial intelligence to medical testing. Having a basic understanding of Bayes' theorem will enable you to learn more about Bayesian statistics as you advance in your career as a data professional.
### Discrete probability distributions
###### Introduction to probability distributions
Data professionals use probability distributions to model different kinds of datasets and to identify significant patterns in data. A probability distribution describes the likelihood of the possible outcomes of a random event. For example the possible outcomes of simple random events like tossing a coin or rolling a die. They can also represent more complex events like the probability of a new medication successfully treating a medical condition.
A random variable represents the values for the possible outcomes of a random event. There are two types of random variables: 
- Discrete random variable has a countable number of possible values. Often discrete variables are whole numbers that can be counted. For example, if you roll a die five times, you can count the number of times the die lands on two. 
- Continuous random variable takes all possible values in some range of numbers. Here, you are dealing with decimal numbers rather than whole numbers. These values are not countable since there is no limit to the possible number of decimal values between, for example 1 and 2. Typically, these are decimal values that can be measured such as height, weight, time or temperature. For example, if you measure the height of a person or object, you can keep on making your measurement more accurate. The height of a person could be 70.2 inches, 70.23 inches, 70.237 inches, or 70.23567 inches. There is no limit to the number of possible values. 
Its not always immediately obvious if a variable is discrete or continuous. You can use the following guidelines to help you choose between the two:
- COUNT the number of outcomes = discrete.
- MEASURE the outcome = continuous.
Discrete distributions represent discrete random variables. Continuous distributions represent continuous random variables. 
Once you know the sample space of a random variable, you can assign probabilities to each of the possible values. In stats, a sample space is the set of all possible values for a random variable. For example:
- Sample space for single coin toss = {Heads, Tails}
- Sample space for single die roll = {1, 2, 3, 4, 5, 6} or a random variable with 6 possible values.
Let's check out an example of a discrete probability distribution. Take the familiar random event of a single die roll:
- Sample space for single die roll = {1, 2, 3, 4, 5, 6} or a random variable with 6 possible values.
- The probability of each outcome is the same, 16.7%. 
##### Discrete probability distribution.
You can display a discrete probability distribution as a table or a graph. The distribution table summarizes the probability for each possible outcome. The top row list each outcome of the die roll and the bottom list the corresponding probability. 
The bar graph or histogram shows the same probability distribution but in a different form. For a discrete probability the random variable is plotted along the X axis (Outcome), and the corresponding probability is plotted along the Y axis (the probability of each Outcome). In this case the X axis represents each possible outcome of a single die roll, one through six. The Y axis represents the probability of each outcome.
Continuous probability distributions and their graphs work a little differently from discrete distributions. This is due to the difference between discrete (random variables that can be counted) and continuous random variables (random variables that can be measured).
The probability distribution for a discrete random variable can tell you the exact probability for each possible value of the variable. For instance, the probability of rolling a die and getting  three is 1/6 or about 16.7%.
The probability distribution for a continuous random variable can only tell you the probability that the variables takes on a range of values. Let's check out an example to learn more. A continuous random variable may have an infinite number of possible values. 
Imagine you want to measure the height of an oak tree you picked at random from a nearby forest. In this example, the height of the tree is a continuous random variable. The tree's height could be say 15 ft, or 15.2 ft, or 15.2187 ft, and so on. You can keep on adding another decimal place to the measurement without limit. 
Now say you want to know the probability that the height of the oak tree is exactly 15.2 ft. Because the height of the tree could be any decimal value between the ranges of 15 ft and 16 ft, the probability that the tree is exactly any single value is essentially zero. In this example, you'll need to use a continuous probability distribution to tell you the probability that the height of the oak tree is in a certain range or interval. Such as between 15 ft and 16 ft.
![[Screenshot_20240305-111309.png|450]]
The probability of any specific value is zero, so it only makes sense to talk about the probabilities of intervals. A convenient way to show the probabilities of a range or intervals of values is with a curve. On a graph, continuous distributions appear as curves. 
![[Screenshot_20240305-111439.png|450]]
You may have heard about the bell curve which refers to the graph for a continuous distribution called the normal distribution. On the X axis the curve refers to the value of the variable you're measuring, in this case, the oak tree height. The Y axis refers to something called probability density. This is a math function that deals with the values of intervals and is not the same thing as probability. 
There is a lot more to learn about probability distributions and how they can help you model different kinds of data.
###### The binomial distribution
Discrete probability distributions represents random events like tossing a coin or rolling a die. Often, the outcomes of discrete events are expressed as whole numbers that can be counted. For example, the number of times a coin lands on heads in 10 tosses.
This is one of the widely used discrete probability distributions. The binomial distribution is a discrete distribution that models the probability of events with only two possible outcomes; success or failure. This definition assumes that each event is independent or does not affect the probability of the others, and the probability of success is the same for each event. For example, the binomial distribution applies to an event like tossing the same coin 10 times in a row. Keep in mind that successes and failures are labels used for convenience. For example, each toss has only two possible outcomes, heads or tails. You could choose to label either heads or tails as a successful outcome based on the need of your analysis. 
Whatever label you apply to your outcomes, it's important to know that they must be mutually exclusive. As a refresher, two outcomes are mutually exclusive if they cannot occur at the same time. You can't get both heads and tails in a single coin toss. Its either one or the other.
Data professionals use the binomial distribution to model data in different fields such as medicine, investing, and machine learning.
For example, data professionals use binomial distribution to model the probability that a new medication generates side effects, a credit card transaction is fraudulent, or stock prices rises or falls in value. In machine learning, the binomial distribution is often used to classify data. For example, a data professional may train an algorithm to recognize whether a digital image of an animal is or is not a cat. The binomial distribution represents a type of random event called binomial experiment. This is a type of random experiment. A random experiment is a process whose outcome cannot be predicted with certainty. All random experiments have three things in common.
- The experiment can have more than one possible outcome.
- You can represent each possible outcome in advance.
- The outcome of the experiment depends on chance.
On the other hand, a binomial experiment has the following attributes:
- The experiment consists of a number of repeat trials.
- Each trial has only two possible outcomes.
- The probability of success is the same for each trial, and each trial is independent. 
An example of a binomial experiment is tossing a coin 10 times in a row. This is a binomial experiment because it has the following features:
- The experiment consists of 10 repeated trials or coin tosses.
- Each trial has only two possible outcomes; heads or tails.
- The probability of success is the same for each trial. If you define success as heads, then the probability of success for each toss is the same; 50%.
- Each trial is independent. The outcome of one coin toss does not affect the outcome of any other coin toss. 
Another example of binomial experiment:
Suppose you want to know how many customers return an item to a department store on a given day. Say 100 customers visit the store each day. Ten percent of all customers who visit the store make a return. You label a return as a success. This is a binomial experiment because there are 100 repeated trials or customer visits. Each trial only has two possible outcomes, return or not return. If you label return a success, the probability of success for each customer visit is the same, 10 percent. Each trial is independent. The outcome of one customer visit does not affect the outcome of any other customer visit. Its important to understand the features of a binomial experiment because the binomial distribution could only model data for this type of event. 
If you are working with data for a different event, you need to use a different type of probability distribution, like the Poisson to model the data. Once you have determined that your distribution is binomial, you can apply the binomial distribution formula to calculate the probability. No need to memorize the formula since you can use your computer to make the calculations.
![[binomial-distribution-formula.png|450]]
In brief, the binomial distribution formula helps you determine the probability of getting the probability of getting a certain number of successful outcomes in a certain number of trials. For example, getting a certain number of heads in a certain number of coin flips. 
In this formula:
- k = refers to the number of successes,
- n = the number of trials,
- p = the probability of a success on a given trial.
- n choose k = refers to the number of ways to obtain k successes in n trials.
![[n-choose-k.png|450]]
Let's explore our departments, for example, to better understand how the formula works. This time, suppose 10% of all customers who visit the store make a return. Imagine that three customers visit the store. You label a return as a success. You can use the formula to determine the probability of getting 0, 1, 2, and 3 returns among the three customers. In the calculation, X refers to the number of returns. If you plug in for the probability, you get:
| X | Probability |
| 0 |  0.729 |
| 1 |  0.243 |
| 3 |  0.001 |
You can then use a histogram to visualize this probability distribution. 
![[histogram-binomial-distribution.png|450]]
For a discrete probability distribution, like the binomial distribution, the random variable is plotted along the x-axis and the corresponding probability is plotted along the y-axis. In this case, the x-axis shows the visits per hour: 0, 1, 2, 3. The y-axis shows the probability of getting each result. The binomial distribution lets you model the events with only two possible outcomes, success or failure.
Identifying the distribution of your data is a key step in any analysis and helps you make informed predictions about the future outcomes.
###### The Poisson distribution
Different kinds of distributions can help you model different kinds of data. When working with a new dataset, try to understand if there is a pattern present in the distribution data. Knowing the distribution of data helps a data professional to choose the machine learning model that works best for better results in less time. Data professionals work with different types of probability distributions.
Poisson distribution is a discrete probability distribution that models the probability that a certain number of events will occur during a specified time period. It can also be used to represent the number of events that occur in a specific space, such as distance, area, or volume. Here, we'll focus on time.
Baron Simeon Denis Poisson, French mathematician derived the Poisson distribution in 1830. He developed the distribution to describe the number of times a gambler would win in difficult game of chance in a large number of tries.
Data professionals use the Poisson distribution to model data such as:
- Calls per hour for a customer service call center.
- Visitors per hour for a website.
- Customers per day at a restaurant.
- Severe storms per month in a city.
The Poisson distribution represents a type of random experiment called a Poisson experiment. It has the following characteristics:
- The number of events in the experiment can be counted.
- The mean number of events that occur during a specific time period is known.
- Each event is independent.
Let's explore an example: 
Imagine you are a data professional working for a large restaurant chain that serves fast food. You know that the drive through service at a restaurant receives an average of two orders per minute. You want to determine the probability that a restaurant will receive a certain number of orders in a given minute.
This is a Poisson experiment because:
- The number of events in the experiment can be counted. You can count the number of orders. 
- The mean number of events that occur during a specific time period is known. There is an average of two orders per minute, each outcome is independent. 
- The probability of one person placing an order does not affect the probability of another person placing an order. 
Once you know that you're working with the Poisson distribution, you can apply the Poisson distribution formula to calculate the probability.
![[poisson-distribution-formula.png|450]]
In brief, the formula helps you determine the probability that a certain number of events occurring during a specific time period. Back to the example:
The restaurant receives an average of 2 orders per minute. You can use the formula to determine the probability of the restaurant receiving 0, 1, 2, or 3 orders in a given minute. Knowing this info may help the restaurant organize staffing for the drive-through. If you plug in for the probability :
| X | Result  |
| 0 | 0.1353 |
| 1 | 0.2707 |
| 2 | 0.2707 |
| 3 | 0.1805 |
You can then use a histogram to visualize the probability distribution. The x-axis shows the number of events, in this case, orders per minute. The y-axis shows the probability of occurrence.
![[histogram-poisson.png|450]]
##### Comparing the two discrete probability distributions
![[poisson vs binomial.png|450]]
###### General guidelines to choosing a probability distribution.
Use the Poisson distribution if you are given the average probability of an event happening for a specific time period. You want to find out the probability of a certain number of events happening in that time period. 
For example: if a call center averages 10 customer service calls per hour, you can use the Poisson distribution to find the probability of getting 12 calls between 2p.m. and 3p.m.
Use the binomial distribution if you are given the exact probability of an event happening, and you want to find out the probability of the event happening a certain number of times in a repeated trial.
For example: if the probability of getting heads for any coin toss is 50%, you can use binomial distribution to find the probability of getting 8 heads in 10 coin tosses.

### Continuous probability distributions
Continuous probability deals with outcomes that can take on all the values in a range of numbers. Typically, these are decimal values which can be measured such as: height, weight, time, or temperature. For example, you can keep on measuring time with more accuracy: 1.1 seconds, 1.12 seconds, 1.1257 seconds, and so on. Here, we'll discuss the most widely used probability distribution in stats, the normal distribution.
The normal distribution is a continuous probability distribution that is symmetrical on both sides of the mean and bell-shaped. The normal distribution is often called the bell curve because its graph has the shape of a bell with a peak at the center and two downward-sloping sides. 
Its also known as the Gaussian distribution after the German mathematician Carl Gauss who first described the formula for the distribution.
The normal distribution is the most common probability distribution in stats because so many different kinds of datasets display a bell-shaped curve. For example, if you randomly sample 100 people you'll discover a normal distribution curve for continuous variables, such as: height, weight, blood pressure, IQ scores, salaries, and more. 
For example, think of the typical results of standardized tests. The majority of people will score close to the average score or mean. Fewer numbers of people will score below or above average farther out from the mean. A very small percentage of people will score extremely high or extremely low. Very far away from the mean. This distribution of scores generates a bell curve. Most of the data values are relatively close to the mean. The farther a value is away from the mean, the less likely it is to occur. 
![[bell-shaped-normal-distribution.png|450]]
On a normal curve, the X-axis refers to the values of the variable you're measuring and the Y-axis refers to how likely you are to observe the value. In the case of test scores, the X-axis is the raw score and the Y-axis is the percentage of the population that gets that score. 
Data professionals use the normal distribution to model all kinds of different datasets in the fields of business, science, government, machine learning, and others. Understanding the normal distribution is also important for more advanced statistical methods such as hypothesis testing and regression analysis. Plus many machine learning algorithms assume that data is normally distributed. 
All normal distributions have the following features:
- the shape is a bell curve.
- the mean is located at the center of the curve.
- the curve is symmetrical on both sides of the center,
- the total area under the curve is equals to 1.
On a normal distribution, the distance of a data point from the mean is often measured in standard deviations. A standard deviation calculates the typical distance of a data point from the mean of your dataset. While the mean refers to the center of your data, the standard deviation measures the spread. As standard deviations becomes larger, data values become spread out from the mean. 
The values on a normal curve are distributed in a regular pattern based on their distance from the mean. This is known as the empirical rule. It states that for a given dataset with a normal distribution;
- 68% of values fall within 1 standard deviation of the mean.
- 95% of values fall within 2 standard deviations of the mean.
- 99.7% of values fall within 3 standard deviations of the mean.
The empirical rule can give you a clear idea of how the values in your dataset are distributed which helps you save time and better understand your data. It is also useful for estimating data, especially for large datasets like height and weight data for an entire population. 
You can use the empirical rule to get an initial estimate of the distribution of values in your dataset such as what percentage of values fall within one, two, or three standard deviations of the mean. This helps you save time and better understand your data. 
Knowing the location of your values on a normal distribution is useful for detecting outliers. Outliers are values that differs significantly from the rest of the data. Typically, data professionals consider values that lie more than three standard deviations below or above the mean to be outliers. Its important to identify outliers because some extreme values may be due to errors in data collection or data processing. These false values may skew the results of your analysis. 
The empirical rule helps you quickly understand the overall distribution of your data values. As a future data professional, you'll use the normal distribution to identify significant patterns in a wide variety of datasets.
#### Model data with the normal distribution
Recall that continuous probability distributions represent continuous random variables, which can take on all the possible values in a range of numbers. Typically, these are decimal numbers that can be measured, such as height, weight, time, or temperature. In this course, we focus on a single continuous probability distribution: the normal distribution, its characteristics, and how the distribution can help you model your data.
##### Continuous probability distributions
Let's discuss the general features of all continuous probability distributions.
###### Probability Density and Probability
A probability function is a mathematical function that provides probabilities for the possible outcomes of a random variable. There are two types of probability functions:
- Probability Mass Function (PMFs) represent discrete random variables.
- Probability Density Functions (PDFs) represent continuous random variables.
A probability function can be represented as an equation or a graph. The graph of a PDF appears as a curve. You have learned about the bell curve, which refers to the graph for a normal distribution. 
The probability distribution for a continuous random variable can only tell you the probability that the variable takes on a range or interval of values. This is because a continuous random variable may have an infinite number of possible values. 
For example, the height of a randomly chosen tree could be 15 ft, or 15.1 ft, or 15.175245 ft, and so on. Lets say you want to know the probability that the height of a randomly chosen tree is exactly 15.1 ft. Because the height of the tree could be any decimal value in a given interval, the probability that the tree is exactly any single value (15.1 ft) is essentially zero. So, for continuous distributions, it only makes sense to talk about the probability of intervals, such as the interval between 14.5 ft and 15.5 ft.
To find the probability of an interval, you calculate the area under the curve that corresponds to the interval. Data professionals typically use statistical software to calculate probabilities on a continuous distribution.
###### The normal distribution
The normal distribution is a continuous probability distribution that is symmetric about the mean and bell-shaped. Its also known as Gaussian distribution. The normal distribution is often called the bell curve because its graph has the shape of a bell, with a peak at the center and two downward sloping sides. It is the most common probability distribution in stats because so many different kinds of datasets display a bell-shaped curve. 
###### Standardize data using z-scores
A z-score is a measure of how many standard deviations below or above the population mean a data point is. It gives you an idea of how far from the mean a data point is. For example, the z-score is 0, if the value is equal to the mean. The z-score is positive if the value is greater than the mean. The z-score is negative if the value is less than the mean. Z-scores help you to standardize your data. In stats, standardization is the process of putting different variables on the same scale. 
Z-scores are also called standard scores because they are based on what's called the standard normal distribution. A standard normal distribution is just a normal distribution with a mean of 0 and a standard deviation of 1. Z-scores typically range from -3 to +3. Standardization is useful because it helps you compare scores from different datasets that may have different units, mean values, and standard deviations. 
Data professionals use z-scores to better understand the relationship between data values within a single dataset and between different datasets. For example, data professionals often use z-scores for anomaly detection, which finds outliers in datasets. 
Application of anomaly detection include finding fraud in financial transactions, flaws in manufacturing products, intrusions in computer networks and more. For example, different customer satisfaction surveys may have different rating scales. One survey could rate a product or service from 1 to 20, another from 500 to 1,500, and a third from 130 to 180. Let's say the same product got a score of 9 on the first survey, 850 on the second and 142 on the third. These numbers don't mean much by themselves, but if you know they all have a z-score of 1, or one standard deviation above the mean, you can meaningfully compare ratings across surveys. A z-score for an individual value can be interpreted as follows:
- A z-score of 1 is one standard deviation above the mean,
- A z-score of 1.5 is 1.5 standard deviations above the mean,
- A z-score of -2.3 is 2.3 standard deviations below the mean.
You can use the z-score formula to calculate a z-score.
![[z-score formula.png|450]]
For example, let's say you take a standardized test, you have a test score of 133. The test has a mean score of 100 and a standard deviation of 15. Assuming a normal distribution, you can use the formula to calculate your z-score. 
133-100 / 15 = 2.2
Your z-score of 2.2 tells you that your test score is 2.2 standard deviations above the mean or average score. Recall that the empirical rule tells you that 95% of values falls within two standard deviations of the mean. Your score of 2.2 is more than two standard deviations above the mean.
Z-score are useful because they give us an idea of how an individual value compares to the rest of the distribution, and it can also give you an idea of how an individual value compared to the mean. As a data professional, you'll use z-scores to help you better understand the relationship between specific values in your dataset. You'll most likely use a programming language like Python to calculate the z-scores on your computer.